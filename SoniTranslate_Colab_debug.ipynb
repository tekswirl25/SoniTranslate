{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lw0EgLex-YZ"
      },
      "source": [
        "# SoniTranslate\n",
        "\n",
        "| Description | Link |\n",
        "| ----------- | ---- |\n",
        "| üéâ Repository | [![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-black?style=flat-square&logo=github)](https://github.com/R3gm/SoniTranslate/) |\n",
        "| üöÄ Online Demo in HF | [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/r3gm/SoniTranslate_translate_audio_of_a_video_content) |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title STEP 00 ‚Ä¢ Select accelerator (CPU/GPU) { display-mode: \"form\" }\n",
        "ACCEL = \"cpu\"  # @param [\"cpu\", \"gpu\"]\n",
        "\n",
        "import os, json\n",
        "\n",
        "env = {\"ACCEL\": ACCEL}\n",
        "# –ù–ï –∑–∞–¥–∞—ë–º PROFILE, —á—Ç–æ–±—ã –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å —Å —Ç–≤–æ–∏–º 07MODE.\n",
        "# TORCH_INDEX_URL –∑–∞–¥–∞–¥–∏–º –ø–æ–∑–∂–µ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏.\n",
        "\n",
        "# –Ω–∞ —Å–µ—Å—Å–∏—é (–¥–ª—è !–∫–æ–º–∞–Ω–¥) ‚Äî –º–æ–∂–µ—Ç –ø—Ä–∏–≥–æ–¥–∏—Ç—å—Å—è\n",
        "os.environ.update(env)\n",
        "\n",
        "# —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è bash-—è—á–µ–π–∫\n",
        "with open(\"/content/soni_accel.env\", \"w\") as f:\n",
        "    for k, v in env.items():\n",
        "        f.write(f'export {k}=\"{v}\"\\n')\n",
        "\n",
        "print(\"ACCEL :\", ACCEL)\n",
        "print(\"Saved :\", \"/content/soni_accel.env\")\n",
        "print(json.dumps(env, indent=2))\n"
      ],
      "metadata": {
        "id": "N4XukP1w41tU",
        "outputId": "55baaa95-8ee3-4a80-bb71-9d0415d8689d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [STEP 01/08] Repo owners & refs ‚Äî CONFIG ONLY\n",
        "#@markdown –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ.\n",
        "\n",
        "OWNER = {\"original\": \"R3gm\", \"fork\": \"tekswirl25\"}\n",
        "USE = \"fork\"  #@param [\"original\", \"fork\"]\n",
        "\n",
        "REPOS = {\n",
        "    \"sonitranslate\": {\"name\": \"SoniTranslate\",   \"ref\": \"main\"},\n",
        "    \"whisperx\":      {\"name\": \"whisperX\",        \"ref\": \"cuda_12_x\"},\n",
        "    \"pyannote\":      {\"name\": \"pyannote-audio\",  \"ref\": \"3.1.1\"},\n",
        "}\n",
        "\n",
        "import os, json\n",
        "\n",
        "for key, info in REPOS.items():\n",
        "    PREFIX = key.upper()\n",
        "    if not os.environ.get(f\"{PREFIX}_URL\"):\n",
        "        os.environ[f\"{PREFIX}_URL\"] = f\"https://github.com/{OWNER[USE]}/{info['name']}.git\"\n",
        "    if not os.environ.get(f\"{PREFIX}_REF\"):\n",
        "        os.environ[f\"{PREFIX}_REF\"] = info[\"ref\"]\n",
        "    # —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: BRANCH –∞–ª–∏–∞—Å –∫ REF\n",
        "    os.environ[f\"{PREFIX}_BRANCH\"] = os.environ[f\"{PREFIX}_REF\"]\n",
        "\n",
        "print(\"MODE:\", USE, \"| OWNER:\", OWNER[USE])\n",
        "print(json.dumps({\n",
        "    \"SONITRANSLATE\": [os.environ[\"SONITRANSLATE_URL\"], os.environ[\"SONITRANSLATE_REF\"]],\n",
        "    \"WHISPERX\":      [os.environ[\"WHISPERX_URL\"],      os.environ[\"WHISPERX_REF\"]],\n",
        "    \"PYANNOTE\":      [os.environ[\"PYANNOTE_URL\"],      os.environ[\"PYANNOTE_REF\"]],\n",
        "}, indent=2, ensure_ascii=False))\n"
      ],
      "metadata": {
        "id": "6OuLxE2huxUU",
        "collapsed": true,
        "outputId": "0a2dafca-d3c7-47c6-dedc-9b4e21d2d2b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 02/08] Quick echo ‚Äî human check (idempotent)\n",
        "set -euo pipefail\n",
        "LOG_DIR=\"${LOG_DIR:-/content/_install_logs}\"\n",
        "mkdir -p \"$LOG_DIR\"\n",
        "\n",
        "{\n",
        "  echo \"SONITRANSLATE: ${SONITRANSLATE_URL:-unset} @ ${SONITRANSLATE_REF:-unset}\"\n",
        "  echo \"WHISPERX:      ${WHISPERX_URL:-unset}      @ ${WHISPERX_REF:-unset}\"\n",
        "  echo \"PYANNOTE:      ${PYANNOTE_URL:-unset}      @ ${PYANNOTE_REF:-unset}\"\n",
        "} | tee \"$LOG_DIR/02_echo.txt\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7kmlb1ME5P67",
        "outputId": "026670fa-1eae-44fb-9ca7-81b35edaedf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [STEP 07WHEELS] External wheels index (optional)\n",
        "import os, json\n",
        "\n",
        "# toggle: 1 = use external wheels repo; 0 = ignore\n",
        "USE_WHEELS_INDEX = \"1\"  # —Å—Ç–∞–≤—å \"0\", –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ\n",
        "\n",
        "# URL –Ω–∞ –ø–∞–ø–∫—É wheels –≤ –ø—É–±–ª–∏—á–Ω–æ–º GitHub-—Ä–µ–ø–æ (RAW)\n",
        "# –ø—Ä–∏–º–µ—Ä: https://raw.githubusercontent.com/<user>/<wheels-repo>/main/wheels\n",
        "WHEELS_INDEX = \"https://raw.githubusercontent.com/tekswirl25/py-wheels-patched/main/wheels\"\n",
        "\n",
        "if USE_WHEELS_INDEX == \"1\" and WHEELS_INDEX.strip():\n",
        "    # pip –ø–æ–Ω–∏–º–∞–µ—Ç --find-links –Ω–∞ HTTP(S); —á–µ—Ä–µ–∑ ENV –¥–æ–±–∞–≤–∏–º –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º find-links\n",
        "    cur = os.environ.get(\"PIP_FIND_LINKS\", \"\").strip()\n",
        "    os.environ[\"PIP_FIND_LINKS\"] = (WHEELS_INDEX if not cur else f\"{WHEELS_INDEX} {cur}\")\n",
        "    os.environ[\"USE_WHEELS_INDEX\"] = \"1\"\n",
        "else:\n",
        "    os.environ.pop(\"USE_WHEELS_INDEX\", None)\n",
        "\n",
        "print(json.dumps({\n",
        "    \"USE_WHEELS_INDEX\": os.environ.get(\"USE_WHEELS_INDEX\", \"0\"),\n",
        "    \"PIP_FIND_LINKS\": os.environ.get(\"PIP_FIND_LINKS\", \"<unset>\")\n",
        "}, indent=2))\n"
      ],
      "metadata": {
        "id": "e3ARLwsk_uPr",
        "outputId": "1a1e08ec-1445-498b-ecd7-a03b8d41141c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 03/08] Remote ref validation ‚Äî branch/tag auto-detect, ENV-compatible\n",
        "set -euo pipefail\n",
        "LOG_DIR=\"${LOG_DIR:-/content/_install_logs}\"\n",
        "mkdir -p \"$LOG_DIR\"\n",
        "\n",
        "check_ref () {\n",
        "  local url=\"$1\" ref=\"$2\" type=\"${3:-}\"\n",
        "  local name\n",
        "  name=\"$(basename \"$url\" .git)\"\n",
        "\n",
        "  # Helper checks\n",
        "  local tag_ok=1 head_ok=1\n",
        "\n",
        "  if [[ -n \"$type\" ]]; then\n",
        "    # Respect explicit type if provided\n",
        "    if [[ \"$type\" == \"tag\" ]]; then\n",
        "      if git ls-remote --tags \"$url\" \"refs/tags/${ref}\" >/dev/null 2>&1; then\n",
        "        echo \"[OK] ${name}: tag '${ref}' found\"\n",
        "      else\n",
        "        echo \"[FAIL] ${name}: tag '${ref}' NOT found\"\n",
        "      fi\n",
        "    else\n",
        "      if git ls-remote --heads \"$url\" \"$ref\" >/dev/null 2>&1; then\n",
        "        echo \"[OK] ${name}: branch '${ref}' found\"\n",
        "      else\n",
        "        echo \"[FAIL] ${name}: branch '${ref}' NOT found\"\n",
        "      fi\n",
        "    fi\n",
        "    return 0\n",
        "  fi\n",
        "\n",
        "  # Auto-detect when REFTYPE is not provided\n",
        "  git ls-remote --tags  \"$url\" \"refs/tags/${ref}\" >/dev/null 2>&1 && tag_ok=0 || tag_ok=1\n",
        "  git ls-remote --heads \"$url\" \"$ref\"              >/dev/null 2>&1 && head_ok=0 || head_ok=1\n",
        "\n",
        "  if [[ $tag_ok -eq 0 && $head_ok -eq 0 ]]; then\n",
        "    echo \"[OK] ${name}: ref '${ref}' exists as BOTH (tag & branch)\"\n",
        "  elif [[ $tag_ok -eq 0 ]]; then\n",
        "    echo \"[OK] ${name}: tag '${ref}' found\"\n",
        "  elif [[ $head_ok -eq 0 ]]; then\n",
        "    echo \"[OK] ${name}: branch '${ref}' found\"\n",
        "  else\n",
        "    echo \"[FAIL] ${name}: ref '${ref}' not found as tag or branch\"\n",
        "  fi\n",
        "}\n",
        "\n",
        "{\n",
        "  check_ref \"${SONITRANSLATE_URL:-}\" \"${SONITRANSLATE_REF:-}\" \"${SONITRANSLATE_REFTYPE:-}\"\n",
        "  check_ref \"${WHISPERX_URL:-}\"      \"${WHISPERX_REF:-}\"      \"${WHISPERX_REFTYPE:-}\"\n",
        "  check_ref \"${PYANNOTE_URL:-}\"      \"${PYANNOTE_REF:-}\"      \"${PYANNOTE_REFTYPE:-}\"\n",
        "} | tee \"$LOG_DIR/03_validate_refs.txt\""
      ],
      "metadata": {
        "id": "5jZZa7G55iDG",
        "outputId": "1c0a2c25-7513-4c75-fd73-62ed8ef91402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 04/08] SAFE CLONE & REQUIREMENTS PREVIEW (NO INSTALL)\n",
        "set -euo pipefail\n",
        "LOG_DIR=\"${LOG_DIR:-/content/_install_logs}\"\n",
        "mkdir -p \"$LOG_DIR\"\n",
        "\n",
        "REPO_DIR=\"/content/SoniTranslate_debug\"\n",
        "URL=\"${SONITRANSLATE_URL:-}\"\n",
        "REF=\"${SONITRANSLATE_REF:-}\"\n",
        "REQ=\"requirements_base.txt\"\n",
        "\n",
        "{\n",
        "  echo \"== repo: $URL @ $REF ==\"\n",
        "\n",
        "  # fresh shallow clone\n",
        "  rm -rf \"$REPO_DIR\"\n",
        "  git clone --depth=2 \"$URL\" \"$REPO_DIR\" -q\n",
        "  cd \"$REPO_DIR\"\n",
        "\n",
        "  # fetch + checkout supports both tag and branch safely\n",
        "  git fetch --depth=2 origin \"$REF\" -q || true\n",
        "  if git rev-parse --verify -q \"refs/remotes/origin/$REF\" >/dev/null; then\n",
        "    git checkout -qf \"origin/$REF\"\n",
        "  elif git rev-parse --verify -q \"refs/tags/$REF\" >/dev/null; then\n",
        "    git checkout -qf \"refs/tags/$REF\"\n",
        "  else\n",
        "    echo \"[WARN] ref '$REF' not found as branch or tag; staying on default clone HEAD\"\n",
        "  fi\n",
        "\n",
        "  if [[ ! -f \"$REQ\" ]]; then\n",
        "    echo \"[info] '$REQ' not found ‚Äî nothing to preview.\"\n",
        "    exit 0\n",
        "  fi\n",
        "\n",
        "  echo \"== current whisperX lines in ${REQ} ==\"\n",
        "  grep -n -E 'git\\+https://github\\.com/.*/whisperX\\.git@.*' \"$REQ\" || echo \"[info] whisperX line not found\"\n",
        "\n",
        "  echo \"== current pyannote lines in ${REQ} ==\"\n",
        "  grep -n -E 'git\\+https://github\\.com/.*/pyannote-audio\\.git@.*' \"$REQ\" || echo \"[info] pyannote line not found\"\n",
        "\n",
        "  cp \"$REQ\" \"${REQ}.preview\"\n",
        "\n",
        "  # Substitute to ENV-refs in preview only (no deps install here)\n",
        "  sed -i \"s|git+https://github.com/.*/whisperX.git@.*|git+${WHISPERX_URL:-https://github.com/placeholder/whisperX.git}@${WHISPERX_REF:-main}|\" \"${REQ}.preview\"\n",
        "  sed -i \"s|git+https://github.com/.*/pyannote-audio.git@.*|git+${PYANNOTE_URL:-https://github.com/placeholder/pyannote-audio.git}@${PYANNOTE_REF:-3.1.1}|\" \"${REQ}.preview\"\n",
        "\n",
        "  echo \"== PREVIEW DIFF (original vs preview) ==\"\n",
        "  diff -u \"$REQ\" \"${REQ}.preview\" || true\n",
        "\n",
        "  rm -f \"${REQ}.preview\"\n",
        "  echo \"[done] preview only; original requirements not modified.\"\n",
        "} | tee \"$LOG_DIR/04_clone_preview.txt\"\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wcSZVAuk5zpZ",
        "outputId": "5ac94ef4-dec2-49ba-f105-d62202487c05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 05/08] SCAN REQUIREMENTS (READ-ONLY AUDIT)\n",
        "set -euo pipefail\n",
        "\n",
        "rm -rf SoniTranslate_scan\n",
        "git clone -q --depth=2 \"${SONITRANSLATE_URL}\" SoniTranslate_scan\n",
        "cd SoniTranslate_scan\n",
        "git fetch -q --depth=2 origin \"${SONITRANSLATE_REF}\" || true\n",
        "git checkout -qf \"origin/${SONITRANSLATE_REF}\" 2>/dev/null || git checkout -qf \"refs/tags/${SONITRANSLATE_REF}\" 2>/dev/null || echo \"[WARN] ref not found; using default HEAD\"\n",
        "\n",
        "echo \"== FILES ==\"\n",
        "find . -maxdepth 2 -type f -name \"requirements*.txt\" -printf \"%P\\n\" | sort || true\n",
        "\n",
        "echo -e \"\\n== GREP: torch with +cu suffix ==\"\n",
        "grep -nE '^torch[^#]*\\+cu[0-9_]+' requirements*.txt */requirements*.txt 2>/dev/null || echo \"[ok] no '+cu' torch pins found\"\n",
        "\n",
        "echo -e \"\\n== GREP: TTS==0.21.1 ==\"\n",
        "grep -nE '(^|[^A-Za-z])TTS==0\\.21\\.1([^A-Za-z]|$)' requirements*.txt */requirements*.txt 2>/dev/null || echo \"[ok] no TTS==0.21.1 pins\"\n",
        "\n",
        "echo -e \"\\n== GREP: whisperX git lines ==\"\n",
        "grep -nE 'git\\+https://github\\.com/.*/whisperX\\.git@.*' requirements*.txt */requirements*.txt 2>/dev/null || echo \"[info] no whisperX git lines found\"\n",
        "\n",
        "echo -e \"\\n== GREP: websockets/opencv hard pins (for awareness) ==\"\n",
        "grep -nE 'websockets|opencv-python' requirements*.txt */requirements*.txt 2>/dev/null || echo \"[info] none\"\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T0JKCCnB7W73",
        "outputId": "e2efa9df-2dc5-4cb2-b32e-0d8d88584c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 06/08] PREVIEW FIXES (NO WRITE)\n",
        "set -euo pipefail\n",
        "\n",
        "rm -rf SoniTranslate_fixpreview\n",
        "git clone -q --depth=2 \"${SONITRANSLATE_URL}\" SoniTranslate_fixpreview\n",
        "cd SoniTranslate_fixpreview\n",
        "git fetch --depth=2 origin \"${SONITRANSLATE_REF}\" -q || true\n",
        "git checkout -qf \"origin/${SONITRANSLATE_REF}\" 2>/dev/null || git checkout -qf \"refs/tags/${SONITRANSLATE_REF}\" 2>/dev/null || echo \"[WARN] ref not found; using default HEAD\"\n",
        "\n",
        "fix_one() {\n",
        "  local file=\"$1\"\n",
        "  [[ -f \"$file\" ]] || return 0\n",
        "  cp \"$file\" \"${file}.preview\"\n",
        "\n",
        "  # 1) torch —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º +cu... ‚Üí –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –ø—Ä–æ—Å—Ç–æ 'torch'\n",
        "  sed -i -E 's/^torch[^#]*\\+cu[0-9_]+/torch/' \"${file}.preview\"\n",
        "\n",
        "  # 2) TTS==0.21.1 ‚Üí –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è colab/python3.12\n",
        "  sed -i -E 's/(^|[^A-Za-z])TTS==0\\.21\\.1([^A-Za-z]|$)/TTS>=0.22,<0.23/g' \"${file}.preview\"\n",
        "\n",
        "  echo \"### DIFF for $file\"\n",
        "  diff -u \"$file\" \"${file}.preview\" || true\n",
        "  rm -f \"${file}.preview\"\n",
        "}\n",
        "\n",
        "for f in requirements*.txt; do fix_one \"$f\"; done\n",
        "echo \"[done] only preview; no files modified.\"\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AQa5Hj4A7vR7",
        "outputId": "6cee1cae-c974-463f-fcd7-2ab34b2a41ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 07/08] CREATE CONSTRAINTS.TXT (READABLE PINS)\n",
        "cat > /content/constraints_sonitranslate.txt <<'TXT'\n",
        "# soft constraints to avoid common conflicts (used with --constraint)\n",
        "# torch —Å—Ç–∞–≤–∏–º –æ—Ç–¥–µ–ª—å–Ω–æ –¥–æ requirements, –ø–æ—ç—Ç–æ–º—É –∑–¥–µ—Å—å –µ–≥–æ –Ω–µ—Ç\n",
        "\n",
        "scipy>=1.11\n",
        "websockets>=15,<16\n",
        "opencv-python==4.10.0.84\n",
        "TTS>=0.22,<0.23\n",
        "transformers>=4.41\n",
        "sentence-transformers>=3.0\n",
        "gradio\n",
        "TXT\n",
        "\n",
        "echo \"== constraints_sonitranslate.txt ==\"\n",
        "cat /content/constraints_sonitranslate.txt\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XdZx1wWz79ki",
        "outputId": "4315f89c-6e30-4e45-f4b5-7369d926e3a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [STEP 07MODE/08] NUMPY ‚Üî GRADIO PROFILE (CONFIG ONLY)\n",
        "#@markdown –ü—Ä–æ—Ñ–∏–ª–∏:\n",
        "#@markdown ‚Ä¢ **upstream** ‚Äî –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ (gradio 4.19.2 ‚Üí numpy 1.26.4)\n",
        "#@markdown ‚Ä¢ **modern** ‚Äî —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç c NumPy 2.x (gradio ‚â• 4.30)\n",
        "PROFILE = \"upstream\"  #@param [\"upstream\", \"modern\"]\n",
        "\n",
        "if PROFILE == \"upstream\":\n",
        "    NUMPY_SPEC  = \"numpy==1.26.4\"\n",
        "    GRADIO_SPEC = \"gradio==4.19.2\"\n",
        "elif PROFILE == \"modern\":\n",
        "    NUMPY_SPEC  = \"numpy>=2.1,<2.3\"\n",
        "    GRADIO_SPEC = \"gradio>=4.30\"\n",
        "else:\n",
        "    raise ValueError(\"PROFILE must be 'upstream' or 'modern'\")\n",
        "\n",
        "import os, json\n",
        "# —É–≤–∞–∂–∞–µ–º –≤–Ω–µ—à–Ω–∏–µ overrides, –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω—ã\n",
        "os.environ.setdefault(\"NUMPY_SPEC\",  NUMPY_SPEC)\n",
        "os.environ.setdefault(\"GRADIO_SPEC\", GRADIO_SPEC)\n",
        "os.environ.setdefault(\"PROFILE\",     PROFILE)\n",
        "\n",
        "print(\"PROFILE:\", os.environ[\"PROFILE\"])\n",
        "print(json.dumps({\n",
        "    \"NUMPY_SPEC\":  os.environ[\"NUMPY_SPEC\"],\n",
        "    \"GRADIO_SPEC\": os.environ[\"GRADIO_SPEC\"]\n",
        "}, indent=2))\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U05n4xk9B6vV",
        "outputId": "4039d690-488d-484d-eccb-6a5813bab354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [STEP 07AUTO/08] PY VERSION AWARE NUMPY/GRADIO (CONFIG ONLY, NON-OVERRIDING)\n",
        "import sys, os, json, re\n",
        "\n",
        "py = sys.version_info\n",
        "py_str = f\"{py.major}.{py.minor}.{py.micro}\"\n",
        "print(\"Detected Python:\", py_str)\n",
        "\n",
        "# –ë–µ—Ä—ë–º —Ç–æ, —á—Ç–æ —É–∂–µ –∑–∞–¥–∞–ª –ø—Ä–æ—Ñ–∏–ª—å (07MODE). –ù–∏—á–µ–≥–æ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º.\n",
        "NUMPY_SPEC  = os.environ.get(\"NUMPY_SPEC\")   # –º–æ–∂–µ—Ç –±—ã—Ç—å None\n",
        "GRADIO_SPEC = os.environ.get(\"GRADIO_SPEC\")  # –º–æ–∂–µ—Ç –±—ã—Ç—å None\n",
        "\n",
        "# –ï—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –Ω–∏—á–µ–≥–æ –Ω–µ –∑–∞–¥–∞–ª ‚Äî –ø–æ–¥–±–µ—Ä—ë–º –¥–µ—Ñ–æ–ª—Ç—ã –ø–æ–¥ –≤–µ—Ä—Å–∏—é Python.\n",
        "# –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: NumPy 2.x –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Python ‚â•3.9, –ø–æ—ç—Ç–æ–º—É 3.12 –û–ö –∏ –¥–ª—è 1.26.4, –∏ –¥–ª—è 2.x.\n",
        "if not NUMPY_SPEC:\n",
        "    if (py.major, py.minor) >= (3, 11):\n",
        "        # —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç; –±–µ–∑–æ–ø–∞—Å–µ–Ω –¥–ª—è 3.11+ –∏ –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É–µ—Ç —Å –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ–º —Å—Ç–µ–∫–æ–≤\n",
        "        NUMPY_SPEC = \"numpy>=2.1,<2.3\"\n",
        "    else:\n",
        "        NUMPY_SPEC = \"numpy==1.26.4\"\n",
        "\n",
        "if not GRADIO_SPEC:\n",
        "    # –¥–µ—Ñ–æ–ª—Ç ¬´–∫–∞–∫ –≤ –∞–ø—Å—Ç—Ä–∏–º–µ¬ª, –µ—Å–ª–∏ –ø—Ä–æ—Ñ–∏–ª—å –µ–≥–æ –Ω–µ –∑–∞–¥–∞–ª\n",
        "    GRADIO_SPEC = \"gradio==4.19.2\"\n",
        "\n",
        "# –õ—ë–≥–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –Ω–µ—Å–æ—Å—Ç—ã–∫–æ–≤–æ–∫ (—Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º)\n",
        "def major_ver(spec: str, name: str):\n",
        "    if not spec: return None\n",
        "    m = re.search(rf\"{name}\\s*([<>=!~]=\\s*)?(\\d+)\\.(\\d+)\", spec.replace(\" \", \"\"), re.I)\n",
        "    return int(m.group(2)) if m else None\n",
        "\n",
        "np_major = major_ver(NUMPY_SPEC, \"numpy\")\n",
        "gr_set   = bool(GRADIO_SPEC)\n",
        "\n",
        "if np_major == 2 and GRADIO_SPEC == \"gradio==4.19.2\":\n",
        "    print(\"[WARN] NumPy 2.x —Å gradio==4.19.2: –µ—Å–ª–∏ –ø–æ–π–º–∞–µ—Ç–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç, –ø–æ–¥–Ω–∏–º–∏—Ç–µ gradio (–Ω–∞–ø—Ä–∏–º–µ—Ä, '>=4.30') –∏–ª–∏ –≤–µ—Ä–Ω–∏—Ç–µ NumPy 1.26.4.\")\n",
        "\n",
        "# –≠–∫—Å–ø–æ—Ä—Ç –±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ —Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω—ã—Ö ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
        "os.environ[\"NUMPY_SPEC\"]  = NUMPY_SPEC\n",
        "os.environ[\"GRADIO_SPEC\"] = GRADIO_SPEC\n",
        "\n",
        "print(json.dumps({\"Python\": py_str, \"NUMPY_SPEC\": NUMPY_SPEC, \"GRADIO_SPEC\": GRADIO_SPEC}, indent=2))\n",
        "\n"
      ],
      "metadata": {
        "id": "7xV8Ov3QHbfu",
        "outputId": "3eca76ef-82e1-4aa5-aec7-ab1a2b0fbed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [STEP 07DBG/08] DEBUG PROFILE ‚Äî manual toggles for secondary deps\n",
        "import os, json\n",
        "\n",
        "# === –¥–≤–æ–π–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏: –º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Ö–∞—Ä–¥–∫–æ–¥ –∏ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å ENV ===\n",
        "\n",
        "# SCIPY_SPEC        = os.environ.get(\"SCIPY_SPEC\")\n",
        "SCIPY_SPEC = \"scipy>=1.11\"  # upstream: ok —Å NumPy 1.26.4; modern (NumPy 2.x): ‚â•1.11/1.13\n",
        "\n",
        "\n",
        "# WEBSOCKETS_SPEC   = os.environ.get(\"WEBSOCKETS_SPEC\")\n",
        "# WEBSOCKETS_SPEC   = \"websockets>=10,<12\"\n",
        "WEBSOCKETS_SPEC   = \"-\"   # —Å–ø–µ—Ü-–∑–Ω–∞—á–µ–Ω–∏–µ ¬´–Ω–µ –ø–∏—Å–∞—Ç—å –≤ constraints¬ª\n",
        "\n",
        "# OPENCV_SPEC       = os.environ.get(\"OPENCV_SPEC\")\n",
        "OPENCV_SPEC       = \"opencv-python==4.10.0.84\"\n",
        "\n",
        "# TTS_SPEC          = os.environ.get(\"TTS_SPEC\")\n",
        "TTS_SPEC          = \"TTS>=0.22,<0.23\"\n",
        "\n",
        "# TRANSFORMERS_SPEC = os.environ.get(\"TRANSFORMERS_SPEC\")\n",
        "# TRANSFORMERS_SPEC = \"transformers>=4.41\"\n",
        "TRANSFORMERS_SPEC = \"transformers>=4.33,<4.37\"  # –¥—Ä—É–∂–∏—Ç —Å tokenizers<0.16\n",
        "\n",
        "# SENT_TR_SPEC      = os.environ.get(\"SENTENCE_TRANSFORMERS_SPEC\")\n",
        "SENT_TR_SPEC      = \"sentence-transformers>=2.2,<3.0\"  # v3 —Ç—Ä–µ–±—É–µ—Ç transformers>=4.41\n",
        "\n",
        "# TOKENIZERS_SPEC   = os.environ.get(\"TOKENIZERS_SPEC\")\n",
        "TOKENIZERS_SPEC   = \"tokenizers>=0.13,<0.16\"    # –ø–æ–¥ faster-whisper==1.0.0\n",
        "\n",
        "# === TORCH trio (torch/torchvision/torchaudio) ===\n",
        "# TORCH_SPEC       = os.environ.get(\"TORCH_SPEC\")\n",
        "TORCH_SPEC       = \"torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1\"\n",
        "\n",
        "# TORCH_INDEX_URL  = os.environ.get(\"TORCH_INDEX_URL\")\n",
        "TORCH_INDEX_URL  = \"https://download.pytorch.org/whl/cpu\"\n",
        "# TORCH_INDEX_URL  = \"https://download.pytorch.org/whl/cu121\"   # –ø—Ä–∏–º–µ—Ä –¥–ª—è CUDA 12.1\n",
        "\n",
        "# OMEGACONF/HYDRA/FAIRSEQ –¥–ª—è requirements_extra\n",
        "# OMEGACONF_SPEC   = os.environ.get(\"OMEGACONF_SPEC\")\n",
        "OMEGACONF_SPEC   = \"-\"\n",
        "# HYDRA_CORE_SPEC  = os.environ.get(\"HYDRA_CORE_SPEC\")\n",
        "HYDRA_CORE_SPEC  = \"-\"\n",
        "# FAIRSEQ_SPEC     = os.environ.get(\"FAIRSEQ_SPEC\")\n",
        "FAIRSEQ_SPEC     = \"-\"\n",
        "\n",
        "\n",
        "def set_if_nonempty(key, val):\n",
        "    \"\"\"Write to ENV only if val is non-empty and not '-' (our 'skip' marker).\"\"\"\n",
        "    if isinstance(val, str):\n",
        "        v = val.strip()\n",
        "        if v and v != \"-\":\n",
        "            os.environ[key] = v\n",
        "\n",
        "# === –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –≤ ENV (—Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –±–µ–∑ '-') ===\n",
        "set_if_nonempty(\"SCIPY_SPEC\",        SCIPY_SPEC)\n",
        "set_if_nonempty(\"WEBSOCKETS_SPEC\",   WEBSOCKETS_SPEC)\n",
        "set_if_nonempty(\"OPENCV_SPEC\",       OPENCV_SPEC)\n",
        "set_if_nonempty(\"TTS_SPEC\",          TTS_SPEC)\n",
        "set_if_nonempty(\"TRANSFORMERS_SPEC\", TRANSFORMERS_SPEC)\n",
        "set_if_nonempty(\"SENTENCE_TRANSFORMERS_SPEC\", SENT_TR_SPEC)\n",
        "set_if_nonempty(\"TOKENIZERS_SPEC\",   TOKENIZERS_SPEC)\n",
        "set_if_nonempty(\"TORCH_SPEC\",        TORCH_SPEC)\n",
        "set_if_nonempty(\"TORCH_INDEX_URL\",   TORCH_INDEX_URL)\n",
        "set_if_nonempty(\"OMEGACONF_SPEC\",    OMEGACONF_SPEC)\n",
        "set_if_nonempty(\"HYDRA_CORE_SPEC\",   HYDRA_CORE_SPEC)\n",
        "set_if_nonempty(\"FAIRSEQ_SPEC\",      FAIRSEQ_SPEC)\n",
        "\n",
        "print(\"== DEBUG PROFILE (effective) ==\")\n",
        "print(json.dumps({\n",
        "    \"NUMPY\":  os.environ.get(\"NUMPY_SPEC\"),    # —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ 07MODE/07AUTO\n",
        "    \"GRADIO\": os.environ.get(\"GRADIO_SPEC\"),   # —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ 07MODE/07AUTO\n",
        "    \"SCIPY\":  os.environ.get(\"SCIPY_SPEC\"),\n",
        "    \"WEBSOCKETS\": os.environ.get(\"WEBSOCKETS_SPEC\"),  # –±—É–¥–µ—Ç None, –µ—Å–ª–∏ \"-\"\n",
        "    \"OPENCV\": os.environ.get(\"OPENCV_SPEC\"),\n",
        "    \"TTS\": os.environ.get(\"TTS_SPEC\"),\n",
        "    \"TRANSFORMERS\": os.environ.get(\"TRANSFORMERS_SPEC\"),\n",
        "    \"SENTENCE-TRANSFORMERS\": os.environ.get(\"SENTENCE_TRANSFORMERS_SPEC\"),\n",
        "    \"TOKENIZERS_SPEC\": os.environ.get(\"TOKENIZERS_SPEC\"),\n",
        "    \"TORCH_SPEC\": os.environ.get(\"TORCH_SPEC\"),\n",
        "    \"TORCH_INDEX_URL\": os.environ.get(\"TORCH_INDEX_URL\"),\n",
        "    \"OMEGACONF_SPEC\": os.environ.get(\"OMEGACONF_SPEC\"),\n",
        "    \"HYDRA_CORE_SPEC\": os.environ.get(\"HYDRA_CORE_SPEC\"),\n",
        "    \"FAIRSEQ_SPEC\": os.environ.get(\"FAIRSEQ_SPEC\"),\n",
        "}, indent=2))\n"
      ],
      "metadata": {
        "id": "EtJFdasP8cQR",
        "outputId": "341f546b-d141-433b-e3a3-a2644c9a3306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 07CONS/08] WRITE CONSTRAINTS FROM ENV (STRICT FOR NUMPY/GRADIO)\n",
        "set -euo pipefail\n",
        "\n",
        ": \"${NUMPY_SPEC?NUMPY_SPEC is not set (run 07MODE/07AUTO).}\"\n",
        ": \"${GRADIO_SPEC?GRADIO_SPEC is not set (run 07MODE/07AUTO).}\"\n",
        "\n",
        "# —á–∏—Ç–∞–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ (–±–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–∏ set -u)\n",
        ": \"${SCIPY_SPEC:=}\"\n",
        ": \"${WEBSOCKETS_SPEC:=}\"\n",
        ": \"${OPENCV_SPEC:=}\"\n",
        ": \"${TTS_SPEC:=}\"\n",
        ": \"${TRANSFORMERS_SPEC:=}\"\n",
        ": \"${SENTENCE_TRANSFORMERS_SPEC:=}\"\n",
        ": \"${TOKENIZERS_SPEC:=}\"\n",
        ": \"${OMEGACONF_SPEC:=}\"\n",
        ": \"${HYDRA_CORE_SPEC:=}\"\n",
        ": \"${FAIRSEQ_SPEC:=}\"\n",
        ": \"${GRADIO_CLIENT_SPEC:=}\"   # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ\n",
        "\n",
        "CONS=\"/content/constraints_sonitranslate.txt\"\n",
        "{\n",
        "  echo \"${NUMPY_SPEC}\"\n",
        "  [[ -n \"${SCIPY_SPEC}\"                  && \"${SCIPY_SPEC}\"                  != \"-\" ]] && echo \"${SCIPY_SPEC}\"\n",
        "  [[ -n \"${WEBSOCKETS_SPEC}\"             && \"${WEBSOCKETS_SPEC}\"             != \"-\" ]] && echo \"${WEBSOCKETS_SPEC}\"\n",
        "  [[ -n \"${OPENCV_SPEC}\"                 && \"${OPENCV_SPEC}\"                 != \"-\" ]] && echo \"${OPENCV_SPEC}\"\n",
        "  [[ -n \"${TTS_SPEC}\"                    && \"${TTS_SPEC}\"                    != \"-\" ]] && echo \"${TTS_SPEC}\"\n",
        "  [[ -n \"${TRANSFORMERS_SPEC}\"           && \"${TRANSFORMERS_SPEC}\"           != \"-\" ]] && echo \"${TRANSFORMERS_SPEC}\"\n",
        "  [[ -n \"${SENTENCE_TRANSFORMERS_SPEC}\"  && \"${SENTENCE_TRANSFORMERS_SPEC}\"  != \"-\" ]] && echo \"${SENTENCE_TRANSFORMERS_SPEC}\"\n",
        "  [[ -n \"${TOKENIZERS_SPEC}\"             && \"${TOKENIZERS_SPEC}\"             != \"-\" ]] && echo \"${TOKENIZERS_SPEC}\"\n",
        "  [[ -n \"${OMEGACONF_SPEC}\"              && \"${OMEGACONF_SPEC}\"              != \"-\" ]] && echo \"${OMEGACONF_SPEC}\"\n",
        "  [[ -n \"${HYDRA_CORE_SPEC}\"             && \"${HYDRA_CORE_SPEC}\"             != \"-\" ]] && echo \"${HYDRA_CORE_SPEC}\"\n",
        "  [[ -n \"${FAIRSEQ_SPEC}\"                && \"${FAIRSEQ_SPEC}\"                != \"-\" ]] && echo \"${FAIRSEQ_SPEC}\"\n",
        "  [[ -n \"${GRADIO_CLIENT_SPEC}\"          && \"${GRADIO_CLIENT_SPEC}\"          != \"-\" ]] && echo \"${GRADIO_CLIENT_SPEC}\"\n",
        "  echo \"${GRADIO_SPEC}\"\n",
        "} > \"$CONS\"\n",
        "\n",
        "echo \"== USING CONSTRAINTS (PROFILE=${PROFILE:-unknown}) ==\"\n",
        "cat \"$CONS\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T6y3FzhvCHbl",
        "outputId": "0589b148-9e74-47c0-b7e1-432246cf7c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 08A/08] PRECHECK UV & GIT (NO INSTALL)\n",
        "set -euo pipefail\n",
        "\n",
        "echo \"== python/pip/uv/git versions ==\"\n",
        "python -V\n",
        "python -m pip -V\n",
        "git --version || true\n",
        "python -c \"import shutil; print('uv on PATH:', bool(shutil.which('uv')))\"\n",
        "\n",
        "echo \"== installing uv if missing ==\"\n",
        "python -m pip install -q --upgrade pip setuptools wheel\n",
        "python -m pip install -q uv\n",
        "python -c \"import shutil; print('uv on PATH (after):', bool(shutil.which('uv')))\"\n",
        "\n",
        "echo \"== env ==\"\n",
        "echo \"SONITRANSLATE_URL = ${SONITRANSLATE_URL}\"\n",
        "echo \"SONITRANSLATE_REF = ${SONITRANSLATE_REF}\"\n",
        "echo \"WHISPERX_URL      = ${WHISPERX_URL}\"\n",
        "echo \"WHISPERX_REF      = ${WHISPERX_REF}\"\n",
        "\n",
        "echo \"== remote ref check ==\"\n",
        "git ls-remote --tags  \"${SONITRANSLATE_URL}\" \"${SONITRANSLATE_REF}\" || git ls-remote --heads \"${SONITRANSLATE_URL}\" \"${SONITRANSLATE_REF}\" || echo \"[warn] ref not found\"\n",
        "git ls-remote --tags  \"${WHISPERX_URL}\"      \"${WHISPERX_REF}\"      || git ls-remote --heads \"${WHISPERX_URL}\"      \"${WHISPERX_REF}\"      || echo \"[warn] ref not found\"\n",
        "\n",
        "echo \"[ok] precheck done\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EOZVKP0k8L-J",
        "outputId": "d2bfda95-5762-4e3e-e9e4-6c63eab1fe05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 08AA/08] QUICK FIX: satisfy IPython 7.x -> jedi>=0.16\n",
        "set -euo pipefail\n",
        "\n",
        "# –†–∞–∑—Ä–µ—à–∏–º –Ω–µ–Ω—É–ª–µ–≤–æ–π –∫–æ–¥ —É python-–±–ª–æ–∫–∞, —á—Ç–æ–±—ã –ø–æ–π–º–∞—Ç—å –µ–≥–æ –≤—Ä—É—á–Ω—É—é:\n",
        "set +e\n",
        "python - <<'PY'\n",
        "import sys\n",
        "try:\n",
        "    import IPython\n",
        "    ver = getattr(IPython, \"__version__\", \"0\")\n",
        "    major = int(ver.split(\".\")[0])\n",
        "    if major == 7:\n",
        "        try:\n",
        "            import jedi  # ok\n",
        "            print(\"IPython 7.x: jedi present -> skip install\")\n",
        "            sys.exit(0)\n",
        "        except Exception:\n",
        "            print(\"IPython 7.x: jedi missing -> need install\")\n",
        "            sys.exit(42)\n",
        "    else:\n",
        "        print(f\"IPython {ver}: not 7.x -> skip install\")\n",
        "        sys.exit(0)\n",
        "except Exception as e:\n",
        "    print(f\"[warn] IPython check failed: {e}\")\n",
        "    sys.exit(0)\n",
        "PY\n",
        "rc=$?\n",
        "set -e\n",
        "\n",
        "if [[ $rc -eq 42 ]]; then\n",
        "  python -m pip install -q \"jedi>=0.16\"\n",
        "  echo \"[ok] installed jedi (for IPython 7.x)\"\n",
        "else\n",
        "  echo \"[skip] no jedi install needed\"\n",
        "fi\n",
        "\n"
      ],
      "metadata": {
        "id": "xuYrgI3CXsX0",
        "outputId": "26afa9b1-9d17-414e-92e0-97faa406ac2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UI (–æ—Å—Ç–∞–≤—å –∫–∞–∫ –µ—Å—Ç—å)\n",
        "#@title Wheel manager (repo/build/skip) ‚Äî Python‚ÜíBash (diagnostic build)\n",
        "MODE = \"repo\"  #@param [\"repo\", \"build\", \"skip\"]\n",
        "REPO_URL = \"https://github.com/tekswirl25/py-wheels-patched/main/wheels/omegaconf-2.0.6-py3-none-any.whl\"  #@param {type:\"string\"}\n",
        "SKIP_IF_PRESENT = True  #@param {type:\"boolean\"}\n",
        "\n",
        "import os, subprocess\n",
        "env = os.environ.copy()\n",
        "env.update({\"MODE\": MODE, \"REPO_URL\": REPO_URL, \"SKIP_IF_PRESENT\": \"1\" if SKIP_IF_PRESENT else \"0\"})\n",
        "\n",
        "bash = r'''#!/usr/bin/env bash\n",
        "set -euo pipefail\n",
        "set -x\n",
        "trap 'echo \"[ERR] line $LINENO: $BASH_COMMAND\" >&2' ERR\n",
        "\n",
        "# ---------- INPUT ----------\n",
        "MODE=\"${MODE:-build}\"\n",
        "REPO_URL=\"${REPO_URL:-}\"\n",
        "SKIP_IF_PRESENT=\"${SKIP_IF_PRESENT:-1}\"\n",
        "PKG=\"omegaconf\"\n",
        "VER=\"2.0.6\"\n",
        "WORKDIR=\"/content/_patch_${PKG}_${VER}\"\n",
        "WHEEL_DIR=\"/content/_wheels\"\n",
        "CURL_RETRY=3\n",
        "CURL_OPTS=(-fSL --retry \"$CURL_RETRY\" --connect-timeout 10)\n",
        "# ---------------------------\n",
        "\n",
        "norm_to_raw_github() {\n",
        "  local url=\"$1\"\n",
        "  url=\"${url%%#*}\"\n",
        "  if [[ \"$url\" == *\"raw.githubusercontent.com\"* ]]; then echo \"$url\"; return; fi\n",
        "  if [[ \"$url\" == *\"github.com\"* ]]; then\n",
        "    local path=\"${url#*github.com/}\"\n",
        "    IFS='/' read -r owner repo a b rest <<<\"$path\"\n",
        "    if [[ \"$a\" == \"blob\" || \"$a\" == \"tree\" ]]; then\n",
        "      echo \"https://raw.githubusercontent.com/${owner}/${repo}/${b}/${rest}\"\n",
        "    else\n",
        "      echo \"https://raw.githubusercontent.com/${owner}/${repo}/${a}/${b}/${rest}\"\n",
        "    fi\n",
        "    return\n",
        "  fi\n",
        "  echo \"$url\"\n",
        "}\n",
        "\n",
        "download_to() {\n",
        "  local url=\"$1\" out=\"$2\"\n",
        "  url=\"${url%%#*}\"\n",
        "  curl \"${CURL_OPTS[@]}\" \"$url\" -o \"$out\"\n",
        "}\n",
        "\n",
        "echo \"== prep ==\"\n",
        "rm -rf \"$WORKDIR\"\n",
        "mkdir -p \"$WORKDIR\" \"$WHEEL_DIR\"\n",
        "cd \"$WORKDIR\"\n",
        "\n",
        "case \"$MODE\" in\n",
        "  skip)\n",
        "    echo \"[skip] wheel step\"\n",
        "    exit 0\n",
        "  ;;\n",
        "\n",
        "  repo)\n",
        "    echo \"== REPO mode ==\"\n",
        "    [[ -n \"$REPO_URL\" ]] || { echo \"[err] REPO_URL is empty\"; exit 1; }\n",
        "    RAW_URL=\"$(norm_to_raw_github \"$REPO_URL\")\"\n",
        "    FNAME=\"${RAW_URL##*/}\"\n",
        "    [[ \"$FNAME\" == *.whl ]] || { echo \"[err] URL not a .whl: $RAW_URL\"; exit 1; }\n",
        "    DEST=\"$WHEEL_DIR/$FNAME\"\n",
        "\n",
        "    if [[ \"$SKIP_IF_PRESENT\" == \"1\" && -f \"$DEST\" ]]; then\n",
        "      echo \"[skip] cached wheel: $DEST\"\n",
        "    else\n",
        "      echo \"== download wheel from repo ==\"\n",
        "      download_to \"$RAW_URL\" \"$DEST\"\n",
        "      echo \"[ok] downloaded: $DEST\"\n",
        "    fi\n",
        "\n",
        "    echo \"== install from local ==\"\n",
        "    python -m pip install -v --no-deps \"$DEST\"\n",
        "\n",
        "    echo \"== verify ==\"\n",
        "    python - <<PY\n",
        "import omegaconf, sys\n",
        "print(\"omegaconf:\", omegaconf.__version__)\n",
        "ok = (omegaconf.__version__ == \"$VER\")\n",
        "print(\"ok:\", ok)\n",
        "sys.exit(0 if ok else 1)\n",
        "PY\n",
        "  ;;\n",
        "\n",
        "  build)\n",
        "    echo \"== BUILD mode ==\"\n",
        "    python -m pip install -q --upgrade pip wheel\n",
        "\n",
        "    echo \"== discover wheel URL from PyPI simple index ==\"\n",
        "    curl -fsSL \"https://pypi.org/simple/${PKG}/\" -o index.html\n",
        "    WHEEL_URL=\"$(python - <<'PY'\n",
        "import re, html\n",
        "p=open(\"index.html\",\"r\",encoding=\"utf-8\",errors=\"ignore\").read()\n",
        "m=re.search(r'href=\"([^\"]*omegaconf-2\\.0\\.6-py3-none-any\\.whl[^\"]*)\"', p, re.I)\n",
        "print(html.unescape(m.group(1)) if m else \"\")\n",
        "PY\n",
        ")\"\n",
        "    [[ -n \"$WHEEL_URL\" ]] || { echo \"[err] wheel URL not found\"; exit 1; }\n",
        "    WHEEL_URL=\"${WHEEL_URL%%#*}\"\n",
        "    case \"$WHEEL_URL\" in\n",
        "      http*) : ;;\n",
        "      *) WHEEL_URL=\"https://files.pythonhosted.org/${WHEEL_URL#*/files.pythonhosted.org/}\";;\n",
        "    esac\n",
        "    echo \"wheel url: $WHEEL_URL\"\n",
        "\n",
        "    echo \"== download wheel ==\"\n",
        "    ORIG=\"${PKG}-${VER}-py3-none-any.orig.whl\"\n",
        "    curl \"${CURL_OPTS[@]}\" \"$WHEEL_URL\" -o \"$ORIG\"\n",
        "\n",
        "    echo \"== unpack with wheel tool ==\"\n",
        "    python -m wheel unpack \"$ORIG\" -d \"$WORKDIR/unpacked\"\n",
        "\n",
        "    # –ù–∞–¥—ë–∂–Ω–æ –Ω–∞—Ö–æ–¥–∏–º —Ü–µ–ª–µ–≤—É—é –ø–∞–ø–∫—É\n",
        "    TARGET_DIR=\"$(ls -d \"$WORKDIR\"/unpacked/${PKG}-${VER} 2>/dev/null || true)\"\n",
        "    if [[ -z \"${TARGET_DIR:-}\" ]]; then\n",
        "      TARGET_DIR=\"$(ls -d \"$WORKDIR\"/unpacked/* | head -n1)\"\n",
        "    fi\n",
        "    [[ -n \"$TARGET_DIR\" ]] || { echo \"[err] unpacked dir not found\"; exit 1; }\n",
        "    echo \"TARGET_DIR=$TARGET_DIR\"\n",
        "\n",
        "    echo \"== patch METADATA (PyYAML >=5.1.* -> >=5.1) ==\"\n",
        "    # –í find –∏—Å–ø–æ–ª—å–∑—É–µ–º -path (–∞ –Ω–µ -name) –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è\n",
        "    META_PATH=\"$(find \"$TARGET_DIR\" -type f -path \"*/${PKG}-${VER}.dist-info/METADATA\" | head -n1)\"\n",
        "    if [[ -z \"${META_PATH:-}\" ]]; then\n",
        "      # fallback: –ª—é–±–∞—è *.dist-info/METADATA\n",
        "      META_PATH=\"$(find \"$TARGET_DIR\" -type f -path \"*/.dist-info/METADATA\" -o -path \"*/[Dd]ist-info/METADATA\" | head -n1)\"\n",
        "    fi\n",
        "    [[ -n \"${META_PATH:-}\" ]] || { echo \"[err] METADATA not found\"; find \"$TARGET_DIR\" -maxdepth 3 -type d -name \"*dist-info\" -print; exit 1; }\n",
        "    echo \"META_PATH=$META_PATH\"\n",
        "\n",
        "    echo \"-- BEFORE --\"; grep -E '^Requires-Dist: PyYAML' \"$META_PATH\" || true\n",
        "    sed -i -E 's/PyYAML[[:space:]]*\\(>=[[:space:]]*5\\.1\\.\\*\\)/PyYAML (>=5.1)/g' \"$META_PATH\"\n",
        "    sed -i -E 's/PyYAML[[:space:]]*\\(>=[[:space:]]*5\\.1[[:space:]]*\\*\\)/PyYAML (>=5.1)/g' \"$META_PATH\"\n",
        "    echo \"-- AFTER  --\"; grep -E '^Requires-Dist: PyYAML' \"$META_PATH\" || true\n",
        "\n",
        "    echo \"== repack with wheel tool (updates RECORD) ==\"\n",
        "    python -m wheel pack \"$TARGET_DIR\" -d \"$WORKDIR\"\n",
        "\n",
        "    # –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –Ω–∞—Ö–æ–¥–∏–º —Å–æ–±—Ä–∞–Ω–Ω—ã–π wheel (–Ω–µ .orig)\n",
        "    mapfile -t WHLS < <(ls -1 \"$WORKDIR\"/${PKG}-${VER}-*.whl | grep -v '\\.orig\\.whl$' || true)\n",
        "    [[ ${#WHLS[@]} -ge 1 ]] || { echo \"[err] patched wheel not created\"; ls -l \"$WORKDIR\"; exit 1; }\n",
        "    WHL_PATCHED=\"${WHLS[0]}\"\n",
        "    echo \"WHL_PATCHED=$WHL_PATCHED\"\n",
        "    ls -l \"$WHL_PATCHED\"\n",
        "\n",
        "    echo \"== install patched wheel ==\"\n",
        "    python -m pip install -v --no-deps \"$WHL_PATCHED\"\n",
        "\n",
        "    echo \"== verify ==\"\n",
        "    python - <<PY\n",
        "import omegaconf, sys\n",
        "print(\"omegaconf:\", omegaconf.__version__)\n",
        "ok = (omegaconf.__version__ == \"$VER\")\n",
        "print(\"ok:\", ok)\n",
        "sys.exit(0 if ok else 1)\n",
        "PY\n",
        "\n",
        "    echo \"== cache patched wheel to /content/_wheels ==\"\n",
        "    OUT=\"$WHEEL_DIR/${PKG}-${VER}-py3-none-any.whl\"\n",
        "    cp -f \"$WHL_PATCHED\" \"$OUT\"\n",
        "    if command -v sha256sum >/dev/null 2>&1; then\n",
        "      sha256sum \"$OUT\" | tee \"$OUT.sha256\" >/dev/null\n",
        "    else\n",
        "      python - <<PY\n",
        "import hashlib, sys\n",
        "p=\"$OUT\"\n",
        "h=hashlib.sha256(open(p,'rb').read()).hexdigest()\n",
        "open(p+'.sha256','w').write(f\"{h}  {p.split('/')[-1]}\\n\")\n",
        "print(h)\n",
        "PY\n",
        "    fi\n",
        "    echo \"Wheel saved to: $WHEEL_DIR\"\n",
        "    echo 'Hint: export PIP_FIND_LINKS=\"/content/_wheels${PIP_FIND_LINKS:+ $PIP_FIND_LINKS}\"'\n",
        "  ;;\n",
        "\n",
        "  *)\n",
        "    echo \"[err] MODE must be repo|build|skip\"\n",
        "    exit 2\n",
        "  ;;\n",
        "esac\n",
        "'''\n",
        "\n",
        "subprocess.run(bash, shell=True, check=True, env=env, executable=\"/bin/bash\")\n"
      ],
      "metadata": {
        "id": "ewEe0bdXLmrf",
        "collapsed": true,
        "outputId": "b77022ca-0293-4ad1-cfd2-a092c8b07a10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [PREPATCH] fetch, patch & install wheel: omegaconf==2.0.6 (pip>=24.1-safe)\n",
        "set -euo pipefail\n",
        "\n",
        "# ---------- SWITCH ----------\n",
        "MODE=\"${MODE:-skip}\"   # –¥–æ–ø—É—Å—Ç–∏–º—ã–µ: skip|build\n",
        "# ----------------------------\n",
        "\n",
        "if [[ \"$MODE\" == \"skip\" ]]; then\n",
        "  echo \"[skip] PREPATCH step (MODE=$MODE)\"\n",
        "  exit 0\n",
        "fi\n",
        "\n",
        "PKG=\"omegaconf\"\n",
        "VER=\"2.0.6\"\n",
        "WORKDIR=\"/content/_patch_${PKG}_${VER}\"\n",
        "WHEEL_DIR=\"/content/_wheels\"\n",
        "\n",
        "echo \"== prep ==\"\n",
        "rm -rf \"$WORKDIR\" \"$WHEEL_DIR\"\n",
        "mkdir -p \"$WORKDIR\" \"$WHEEL_DIR\"\n",
        "cd \"$WORKDIR\"\n",
        "\n",
        "echo \"== ensure tools ==\"\n",
        "python -m pip install -q --upgrade pip wheel\n",
        "\n",
        "echo \"== discover wheel URL from PyPI simple index ==\"\n",
        "curl -fsSL \"https://pypi.org/simple/${PKG}/\" -o index.html\n",
        "WHEEL_URL=\"$(python - <<'PY'\n",
        "import re, html\n",
        "p = open(\"index.html\",\"r\",encoding=\"utf-8\",errors=\"ignore\").read()\n",
        "m = re.search(r'href=\"([^\"]*omegaconf-2\\.0\\.6-py3-none-any\\.whl[^\"]*)\"', p, re.I)\n",
        "print(html.unescape(m.group(1)) if m else \"\")\n",
        "PY\n",
        ")\"\n",
        "[[ -n \"$WHEEL_URL\" ]] || { echo \"[err] wheel URL not found\"; exit 1; }\n",
        "case \"$WHEEL_URL\" in http*) : ;; *) WHEEL_URL=\"https://files.pythonhosted.org/${WHEEL_URL#*/files.pythonhosted.org/}\";; esac\n",
        "echo \"wheel url: $WHEEL_URL\"\n",
        "\n",
        "echo \"== download wheel ==\"\n",
        "curl -fSLo \"${PKG}-${VER}-py3-none-any.orig.whl\" \"$WHEEL_URL\"\n",
        "\n",
        "echo \"== unpack with wheel tool ==\"\n",
        "python -m wheel unpack \"${PKG}-${VER}-py3-none-any.orig.whl\" -d \"$WORKDIR/unpacked\"\n",
        "TARGET_DIR=\"$(ls -d \"$WORKDIR\"/unpacked/${PKG}-${VER} 2>/dev/null)\"\n",
        "[[ -n \"${TARGET_DIR:-}\" ]] || { echo \"[err] unpacked dir not found\"; exit 1; }\n",
        "\n",
        "echo \"== patch METADATA (PyYAML >=5.1.* -> >=5.1) ==\"\n",
        "META_PATH=\"$(find \"$TARGET_DIR\" -maxdepth 2 -type f -path \"*/${PKG}-${VER}.dist-info/METADATA\" | head -n1)\"\n",
        "[[ -n \"${META_PATH:-}\" ]] || { echo \"[err] METADATA not found\"; exit 1; }\n",
        "# –¥–æ –ø–∞—Ç—á–∞: –ø–æ–∫–∞–∂–µ–º —Å—Ç—Ä–æ–∫–∏ —Å PyYAML\n",
        "echo \"-- BEFORE --\"; grep -E '^Requires-Dist: PyYAML' \"$META_PATH\" || true\n",
        "# –ø–∞—Ç—á–∏–º\n",
        "sed -i -E 's/PyYAML[[:space:]]*\\(>=[[:space:]]*5\\.1\\.\\*\\)/PyYAML (>=5.1)/g' \"$META_PATH\"\n",
        "echo \"-- AFTER  --\"; grep -E '^Requires-Dist: PyYAML' \"$META_PATH\" || true\n",
        "\n",
        "echo \"== repack with wheel tool (updates RECORD) ==\"\n",
        "python -m wheel pack \"$TARGET_DIR\" -d \"$WORKDIR\"\n",
        "WHL_PATCHED=\"$(ls -1 \"$WORKDIR\"/${PKG}-${VER}-*.whl | grep -v '\\.orig\\.whl$' | head -n1)\"\n",
        "[[ -n \"${WHL_PATCHED:-}\" ]] || { echo \"[err] patched wheel not created\"; exit 1; }\n",
        "ls -l \"$WHL_PATCHED\"\n",
        "\n",
        "echo \"== install patched wheel ==\"\n",
        "# –í–ê–ñ–ù–û: —Å—Ç–∞–≤–∏–º –ø–∞—Ç—á–µ–Ω–Ω—ã–π, –ù–ï .orig\n",
        "python -m pip install -v --no-deps \"$WHL_PATCHED\"\n",
        "\n",
        "echo \"== verify ==\"\n",
        "python - <<'PY'\n",
        "import omegaconf\n",
        "print(\"omegaconf:\", omegaconf.__version__)\n",
        "print(\"ok:\", omegaconf.__version__==\"2.0.6\")\n",
        "PY\n",
        "\n",
        "echo \"== cache patched wheel to /content/_wheels ==\"\n",
        "cp -f \"$WHL_PATCHED\" \"$WHEEL_DIR/omegaconf-${VER}-py3-none-any.whl\"\n",
        "sha256sum \"$WHEEL_DIR/omegaconf-${VER}-py3-none-any.whl\" | tee \"$WHEEL_DIR/omegaconf-${VER}-py3-none-any.whl.sha256\" >/dev/null\n",
        "echo \"Wheel saved to: $WHEEL_DIR\"\n",
        "echo 'Hint for STEP 08: export PIP_FIND_LINKS=\"/content/_wheels${PIP_FIND_LINKS:+ $PIP_FIND_LINKS}\"'\n"
      ],
      "metadata": {
        "id": "JoenvxlbADun",
        "outputId": "a864ffd4-2c42-45bb-f3ef-0dbadf150e6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "export LIVE_MODE=compact\n",
        "export START_LINES=40\n",
        "export INSTALL_EXTRAS=0   # –Ω–µ —Ç—è–Ω–µ–º fairseq/extra –Ω–∞ –ø–µ—Ä–≤–æ–º –ø—Ä–æ–≥–æ–Ω–µ\n",
        "export ROTATE_LOGS=1      # —Å–æ—Ö—Ä–∞–Ω–∏–º –ø—Ä–æ—à–ª—ã–µ –ª–æ–≥–∏, –µ—Å–ª–∏ –±—ã–ª–∏\n"
      ],
      "metadata": {
        "id": "VigPiqjwti8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 08/08] DRY INSTALL ON CPU (ISOLATED COPY, VERBOSE LOGS)\n",
        "# profile-driven; pins —Ç–æ–ª—å–∫–æ –∏–∑ 07MODE/07AUTO/07CONS; –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–æ–≤ –∑–¥–µ—Å—å\n",
        "set -euo pipefail\n",
        "\n",
        "LOG_DIR=\"/content/_install_logs\"\n",
        "\n",
        "# --- –†–æ—Ç–∞—Ü–∏—è —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ) –∏ —á–∏—Å—Ç—ã–π —Å—Ç–∞—Ä—Ç ---\n",
        "if [[ \"${ROTATE_LOGS:-0}\" = \"1\" && -d \"$LOG_DIR\" ]]; then\n",
        "  ts=\"$(date +%Y%m%d_%H%M%S)\"\n",
        "  mv \"$LOG_DIR\" \"${LOG_DIR}_$ts\" || true\n",
        "fi\n",
        "rm -rf \"$LOG_DIR\"\n",
        "mkdir -p \"$LOG_DIR\"\n",
        ": > \"$LOG_DIR/commands.log\"\n",
        ": > \"$LOG_DIR/combined.log\"\n",
        "\n",
        "echo \"Python: $(python -V)\"\n",
        "echo \"PIP_CONSTRAINT=${PIP_CONSTRAINT:-<unset>}\"\n",
        "echo \"PROFILE=${PROFILE:-<unset>}\"\n",
        "echo \"NUMPY_SPEC=${NUMPY_SPEC:-<unset>}\"\n",
        "echo \"GRADIO_SPEC=${GRADIO_SPEC:-<unset>}\"\n",
        "echo \"=== ACTIVE CONSTRAINTS FILE ===\"\n",
        "test -s /content/constraints_sonitranslate.txt || { echo \"ERROR: /content/constraints_sonitranslate.txt missing\"; exit 2; }\n",
        "sed -n '1,120p' /content/constraints_sonitranslate.txt\n",
        "\n",
        "# –ª–æ–∫–∞–ª—å–Ω—ã–µ –∫–æ–ª—ë—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–ø–∞—Ç—á–µ–Ω–Ω—ã–π omegaconf)\n",
        "export PIP_FIND_LINKS=\"/content/_wheels${PIP_FIND_LINKS:+ $PIP_FIND_LINKS}\"\n",
        "export PIP_DISABLE_PIP_VERSION_CHECK=1\n",
        "export PIP_PROGRESS_BAR=on\n",
        "export PIP_USE_PEP517=1\n",
        "export PIP_PREFER_BINARY=1\n",
        "export PYTHONUNBUFFERED=1\n",
        "\n",
        "# –†–µ–∂–∏–º –≤—ã–≤–æ–¥–∞: compact|full (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é compact ‚Äî –Ω–µ –¥—É—à–∏—Ç –Ω–æ—É—Ç–±—É–∫)\n",
        "export LIVE_MODE=\"${LIVE_MODE:-compact}\"\n",
        "export START_LINES=\"${START_LINES:-60}\"\n",
        "\n",
        "on_fail() {\n",
        "  echo \"\"\n",
        "  echo \"===== INSTALL FAILED ‚Äî LAST 200 LINES OF LOGS =====\"\n",
        "  shopt -s nullglob\n",
        "  for f in \"$LOG_DIR\"/*.log; do\n",
        "    echo \"--- $(basename \"$f\") ---\"\n",
        "    tail -n 200 \"$f\" || true\n",
        "  done\n",
        "  echo \"===== DIR TREE =====\"\n",
        "  (set +e; ls -R . | sed 's/^/    /')\n",
        "}\n",
        "trap on_fail ERR\n",
        "\n",
        "# –ü–æ—Ç–æ–∫–æ–≤—ã–π –∑–∞–ø—É—Å–∫: –∏ –≤ –Ω–æ—É—Ç–±—É–∫ (–∞–∫–∫—É—Ä–∞—Ç–Ω–æ), –∏ –≤ –æ–±—â–∏–π –ª–æ–≥; –ø–ª—é—Å per-step .stdout.log –∏ .errors.log\n",
        "run() {\n",
        "  local cmd=\"$*\"\n",
        "  local tag\n",
        "  tag=\"$(echo \"$cmd\" | sed -E 's/[^A-Za-z0-9_.-]+/_/g' | cut -c1-50)\"\n",
        "  local outlog=\"$LOG_DIR/step_${tag}.stdout.log\"\n",
        "  local errlog=\"$LOG_DIR/step_${tag}.errors.log\"\n",
        "\n",
        "  echo -e \"\\n+ $cmd\" | tee -a \"$LOG_DIR/commands.log\"\n",
        "\n",
        "  set -o pipefail\n",
        "  if [[ \"${LIVE_MODE}\" = \"full\" ]]; then\n",
        "    bash -c \"$cmd\" 2>&1 | tee -a \"$LOG_DIR/combined.log\" | tee \"$outlog\"\n",
        "    rc=${PIPESTATUS[0]}\n",
        "  else\n",
        "    # —Ç–∏—Ö–∏–π —Ä–µ–∂–∏–º: –ø–∏—à–µ–º –≤ –ª–æ–≥–∏, –≤ –Ω–æ—É—Ç–±—É–∫ ‚Äî —Ç–æ–ª—å–∫–æ head/tail;\n",
        "    # –í–ê–ñ–ù–û: –±–µ–∑ –ø–æ–¥—à–µ–ª–ª–∞; –≥–ª—É—à–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π tee, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å PIPESTATUS\n",
        "    bash -c \"$cmd\" 2>&1 | tee -a \"$LOG_DIR/combined.log\" | tee \"$outlog\" >/dev/null\n",
        "    rc=${PIPESTATUS[0]}\n",
        "    echo \"   ‚Ü≥ log: $(basename \"$outlog\")\"\n",
        "    echo \"----- first ${START_LINES} lines -----\"; head -n \"${START_LINES}\" \"$outlog\" || true\n",
        "    echo \"--------------- tail ---------------\";   tail -n 20 \"$outlog\" || true\n",
        "  fi\n",
        "  set +o pipefail\n",
        "\n",
        "  # —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å errors.log –Ω–∞ –æ—Å–Ω–æ–≤–µ stdout-—à–∞–≥–∞\n",
        "  grep -i -E '(^|\\[[^]]+\\]\\s*)(ERROR|WARNING):|Traceback|Cannot install|ResolutionImpossible' \"$outlog\" > \"$errlog\" || true\n",
        "  [[ -s \"$errlog\" ]] && echo \"   ‚Ü≥ errors: $(basename \"$errlog\") (non-empty)\" || echo \"   ‚Ü≥ errors: $(basename \"$errlog\") (empty)\"\n",
        "\n",
        "  return \"${rc}\"\n",
        "}\n",
        "\n",
        "# –í—Å–ø–æ–º–æ–≥–∞–ª–∫–∞ –¥–ª—è –≤—ã–∂–∏–º–∫–∏ –∏–∑ pip --log (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)\n",
        "extract_errors() {\n",
        "  local src=\"$1\" dst=\"$2\"\n",
        "  grep -i -E '(^|\\[[^]]+\\]\\s*)(ERROR|WARNING):|Cannot install|ResolutionImpossible' \"$src\" > \"$dst\" 2>/dev/null || true\n",
        "}\n",
        "\n",
        "echo \"== ENV ==\"\n",
        "echo \"SONITRANSLATE: ${SONITRANSLATE_URL} @ ${SONITRANSLATE_REF}\"\n",
        "echo \"WHISPERX:      ${WHISPERX_URL} @ ${WHISPERX_REF}\"\n",
        "echo \"PYANNOTE:      ${PYANNOTE_URL} @ ${PYANNOTE_REF}\"\n",
        "echo \"LOG_DIR:       ${LOG_DIR}\"\n",
        "echo \"LIVE_MODE:     ${LIVE_MODE}\"\n",
        "echo \"PIP_FIND_LINKS:${PIP_FIND_LINKS:-<unset>}\"\n",
        "\n",
        "# 0) bootstrap\n",
        "run \"python -m pip install -v --upgrade pip wheel uv --log $LOG_DIR/pip_bootstrap.log\"\n",
        "extract_errors \"$LOG_DIR/pip_bootstrap.log\" \"$LOG_DIR/pip_bootstrap_errors.log\"\n",
        "run \"python -m pip install -v 'setuptools<81' --log $LOG_DIR/pip_setuptools_compat.log\"\n",
        "extract_errors \"$LOG_DIR/pip_setuptools_compat.log\" \"$LOG_DIR/pip_setuptools_compat_errors.log\"\n",
        "\n",
        "# 1) pre-pin numpy + gradio (–±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö constraints; gradio ‚Äî –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)\n",
        "if [[ -z \"${NUMPY_SPEC:-}\" || -z \"${GRADIO_SPEC:-}\" ]]; then\n",
        "  echo \"ERROR: NUMPY_SPEC/GRADIO_SPEC not set (run 07MODE/07AUTO/07CONS).\"\n",
        "  exit 3\n",
        "fi\n",
        "run \"env -u PIP_CONSTRAINT uv run python -m pip install -v '${NUMPY_SPEC}'  --log $LOG_DIR/pip_prepin_numpy.log\"\n",
        "extract_errors \"$LOG_DIR/pip_prepin_numpy.log\" \"$LOG_DIR/pip_prepin_numpy_errors.log\"\n",
        "run \"env -u PIP_CONSTRAINT uv run python -m pip install -v '${GRADIO_SPEC}' --no-deps --log $LOG_DIR/pip_prepin_gradio.log\"\n",
        "extract_errors \"$LOG_DIR/pip_prepin_gradio.log\" \"$LOG_DIR/pip_prepin_gradio_errors.log\"\n",
        "\n",
        "# (–æ–ø—Ü.) docopt (–∫—Ä–æ—à–µ—á–Ω—ã–π; –±–µ–∑ only-binary, –∏–Ω–∞—á–µ –Ω–µ –Ω–∞–π–¥—ë—Ç –∫–æ–ª—ë—Å–∞)\n",
        "run \"env -u PIP_CONSTRAINT uv run python -m pip install -v 'docopt>=0.6.2' --log $LOG_DIR/pip_docopt.log || true\"\n",
        "extract_errors \"$LOG_DIR/pip_docopt.log\" \"$LOG_DIR/pip_docopt_errors.log\"\n",
        "\n",
        "# 2) CPU/GPU torch-—Ç—Ä–æ–π–∫–∞ (–≤–µ—Ä—Å–∏–∏ –∑–∞–¥–∞–≤–∞–π –≤ 07DBG –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)\n",
        "TORCH_INDEX_URL=\"${TORCH_INDEX_URL:-https://download.pytorch.org/whl/cpu}\"\n",
        "TORCH_SPEC=\"${TORCH_SPEC:-torch torchvision torchaudio}\"\n",
        "run \"uv run python -m pip install -v --index-url '${TORCH_INDEX_URL}' ${TORCH_SPEC} --log $LOG_DIR/pip_torch.log\"\n",
        "extract_errors \"$LOG_DIR/pip_torch.log\" \"$LOG_DIR/pip_torch_errors.log\"\n",
        "\n",
        "# 3) —á–∏—Å—Ç–∞—è –∫–æ–ø–∏—è –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
        "run \"rm -rf SoniTranslate_installtest\"\n",
        "run \"git clone -q --depth=2 '${SONITRANSLATE_URL}' SoniTranslate_installtest\"\n",
        "cd SoniTranslate_installtest\n",
        "git fetch -q --depth=2 origin \"${SONITRANSLATE_REF}\" || true\n",
        "git checkout -qf \"origin/${SONITRANSLATE_REF}\" 2>/dev/null || git checkout -qf \"refs/tags/${SONITRANSLATE_REF}\" 2>/dev/null || echo \"[WARN] ref not found; using default HEAD\"\n",
        "\n",
        "# 4) –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∫–∏ –¢–û–õ–¨–ö–û –≤ –∫–æ–ø–∏–∏ requirements\n",
        "run \"sed -i \\\"s|git+https://github.com/.*/whisperX.git@.*|git+${WHISPERX_URL}@${WHISPERX_REF}|\\\" requirements_base.txt\"\n",
        "run \"sed -i \\\"s|git+https://github.com/.*/pyannote-audio.git@.*|git+${PYANNOTE_URL}@${PYANNOTE_REF}|\\\" requirements_base.txt\"\n",
        "run \"sed -i -E 's/^torch[^#]*\\\\+cu[0-9_]+/torch/' requirements_base.txt\"\n",
        "run \"sed -i -E 's/(^|[^A-Za-z])TTS==0\\\\.21\\\\.1([^A-Za-z]|$)/TTS>=0.22,<0.23/g' requirements*.txt\"\n",
        "\n",
        "# 4b) –Ω–µ –¥–∞—ë–º pip —Ä–µ–∑–æ–ª–≤–∏—Ç—å gradio –∑–∞–Ω–æ–≤–æ\n",
        "run \"sed -i -E 's/^([[:space:]]*gradio[[:space:]]*==[[:space:]]*[0-9.]+[[:space:]]*)/# (preinstalled) \\\\1/' requirements_base.txt\"\n",
        "run \"sed -i -E 's/^([[:space:]]*gradio[[:space:]]*==[[:space:]]*[0-9.]+[[:space:]]*)/# (preinstalled) \\\\1/' requirements_extra.txt || true\"\n",
        "\n",
        "# 4c) –≤–∏—Ç—Ä–∏–Ω–∞ –¥–ª—è –¥–µ–±–∞–≥–∞\n",
        "echo \"=== REQUIREMENTS SNAPSHOT (after sed) ===\"\n",
        "grep -nE '(^|[[:space:]])(gradio|numpy|websockets|pyannote|docopt)|(^|[[:space:]])(-c|--constraint)[[:space:]]' requirements*.txt || true\n",
        "\n",
        "# 5) —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ü–†–û–ï–ö–¢–ê –ø–æ–¥ constraints\n",
        "INSTALL_EXTRAS=\"${INSTALL_EXTRAS:-0}\"\n",
        "\n",
        "run \"env -u PIP_ONLY_BINARY uv run python -m pip install -v -r requirements_base.txt  --constraint /content/constraints_sonitranslate.txt --log $LOG_DIR/pip_req_base.log\"\n",
        "extract_errors \"$LOG_DIR/pip_req_base.log\" \"$LOG_DIR/pip_req_base_errors.log\"\n",
        "\n",
        "if [[ \"$INSTALL_EXTRAS\" = \"1\" ]]; then\n",
        "  # –≤—Ä–µ–º–µ–Ω–Ω—ã–π –¥–∞—É–Ω–≥—Ä–µ–π–¥ pip –¥–ª—è fairseq/hydra (—Å—Ç–∞—Ä—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)\n",
        "  run \"uv run python -m pip install -v 'pip<24.1' --log $LOG_DIR/pip_downgrade_for_extra.log\"\n",
        "  extract_errors \"$LOG_DIR/pip_downgrade_for_extra.log\" \"$LOG_DIR/pip_downgrade_for_extra_errors.log\"\n",
        "\n",
        "  run \"env -u PIP_ONLY_BINARY uv run python -m pip install -v -r requirements_extra.txt --constraint /content/constraints_sonitranslate.txt --log $LOG_DIR/pip_req_extra.log || true\"\n",
        "  extract_errors \"$LOG_DIR/pip_req_extra.log\" \"$LOG_DIR/pip_req_extra_errors.log\"\n",
        "else\n",
        "  echo \"[skip] requirements_extra.txt (INSTALL_EXTRAS=0)\"\n",
        "fi\n",
        "\n",
        "# 6) sanity-–∏–º–ø–æ—Ä—Ç—ã\n",
        "python - << 'PY'\n",
        "import sys, os, numpy, torch, gradio\n",
        "print(\"python:\", sys.version.split()[0])\n",
        "print(\"torch:\", torch.__version__, \"| cuda_available:\", torch.cuda.is_available())\n",
        "print(\"numpy:\", numpy.__version__)\n",
        "print(\"gradio:\", gradio.__version__)\n",
        "print(\"PROFILE:\", os.environ.get(\"PROFILE\"))\n",
        "PY\n",
        "\n",
        "echo \"\"\n",
        "echo \"[ok] install test on CPU completed\"\n",
        "echo \"Logs saved in: $LOG_DIR\"\n"
      ],
      "metadata": {
        "id": "oiFH7SPoqq0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfdfb6c-d103-4d31-b183-3bbcb2a9105a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# [STEP 08 OPTIONAL /08] isolated fairseq env (pin torch; fairseq --no-deps)\n",
        "set -euo pipefail\n",
        "\n",
        "ENV_DIR=\"/content/_fairseq_env\"\n",
        "LOG=\"/content/_install_logs/fairseq_env_install.log\"\n",
        "mkdir -p \"$(dirname \"$LOG\")\"\n",
        ": > \"$LOG\"\n",
        "\n",
        "echo \"== create isolated env ==\" | tee -a \"$LOG\"\n",
        "FALLBACK=0\n",
        "if command -v uv >/dev/null 2>&1; then\n",
        "  uv venv \"$ENV_DIR\" >>\"$LOG\" 2>&1 || { echo \"[warn] uv venv failed, fallback to virtualenv\" | tee -a \"$LOG\"; FALLBACK=1; }\n",
        "else\n",
        "  FALLBACK=1\n",
        "fi\n",
        "if [[ \"$FALLBACK\" = \"1\" ]]; then\n",
        "  python -m pip install -q virtualenv >>\"$LOG\" 2>&1\n",
        "  python -m virtualenv --download \"$ENV_DIR\" >>\"$LOG\" 2>&1\n",
        "fi\n",
        "\n",
        "# shellcheck disable=SC1090\n",
        "source \"$ENV_DIR/bin/activate\"\n",
        "\"$ENV_DIR/bin/python\" -V | tee -a \"$LOG\" || true\n",
        "\n",
        "# pip –≤ venv\n",
        "if ! \"$ENV_DIR/bin/python\" -m pip -V >/dev/null 2>&1; then\n",
        "  \"$ENV_DIR/bin/python\" -m ensurepip --upgrade >/dev/null 2>&1 || {\n",
        "    curl -sS https://bootstrap.pypa.io/get-pip.py -o /tmp/get-pip.py\n",
        "    \"$ENV_DIR/bin/python\" /tmp/get-pip.py >>\"$LOG\" 2>&1\n",
        "  }\n",
        "fi\n",
        "\"$ENV_DIR/bin/python\" -m pip install -q \"pip<24.1\" \"setuptools<81\" wheel >>\"$LOG\" 2>&1\n",
        "\n",
        "# –ª–æ–∫–∞–ª—å–Ω—ã–µ –∫–æ–ª—ë—Å–∞ (–ø–∞—Ç—á-omegaconf)\n",
        "if [[ -d /content/_wheels ]]; then\n",
        "  export PIP_FIND_LINKS=\"/content/_wheels${PIP_FIND_LINKS:+ $PIP_FIND_LINKS}\"\n",
        "  echo \"PIP_FIND_LINKS=${PIP_FIND_LINKS}\" | tee -a \"$LOG\"\n",
        "fi\n",
        "\n",
        "# 1) –ü–ò–ù–´: torch –∏ —Å–≤—è–∑–∫–∞ hydra/omegaconf\n",
        "TORCH_INDEX_URL=\"${FAIRSEQ_TORCH_INDEX_URL:-https://download.pytorch.org/whl/cpu}\"\n",
        "TORCH_SPEC=\"${FAIRSEQ_TORCH_SPEC:-torch==2.5.1}\"\n",
        "echo \"== install torch in venv == ($TORCH_SPEC @ $TORCH_INDEX_URL)\" | tee -a \"$LOG\"\n",
        "\"$ENV_DIR/bin/python\" -m pip install -q --index-url \"$TORCH_INDEX_URL\" $TORCH_SPEC >>\"$LOG\" 2>&1 || true\n",
        "\n",
        "# –°—Ç–∞—Ä—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: —Ä–∞–±–æ—Ç–∞–µ–º —Å pip<24.1, –±–µ—Ä—ë–º –Ω–∞—à wheel –æmegaconf 2.0.6 (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
        "echo \"== install omegaconf + hydra-core ==\" | tee -a \"$LOG\"\n",
        "\"$ENV_DIR/bin/python\" -m pip install -q \"omegaconf==2.0.6\" \"hydra-core==1.0.7\" >>\"$LOG\" 2>&1\n",
        "\n",
        "# 2) fairseq –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (—á—Ç–æ–±—ã –ù–ï —Ç—Ä–æ–≥–∞–ª torch –∏ –∫–æ)\n",
        "echo \"== install fairseq (no-deps) ==\" | tee -a \"$LOG\"\n",
        "\"$ENV_DIR/bin/python\" -m pip install -v \"fairseq==0.12.2\" --no-deps >>\"$LOG\" 2>&1\n",
        "\n",
        "echo \"== sanity check ==\" | tee -a \"$LOG\"\n",
        "\"$ENV_DIR/bin/python\" - <<'PY' | tee -a \"$LOG\"\n",
        "import importlib, json\n",
        "def ver(name, imp=None):\n",
        "    try:\n",
        "        m = importlib.import_module(imp or name)\n",
        "        return getattr(m, \"__version__\", \"unknown\")\n",
        "    except Exception as e:\n",
        "        return f\"ERROR: {e}\"\n",
        "mods = {\n",
        "  \"torch\": ver(\"torch\"),\n",
        "  \"omegaconf\": ver(\"omegaconf\"),\n",
        "  \"hydra\": ver(\"hydra\"),\n",
        "  \"fairseq\": ver(\"fairseq\"),\n",
        "}\n",
        "print(json.dumps(mods, indent=2))\n",
        "PY\n",
        "\n",
        "echo \"\"\n",
        "echo \"[ok] fairseq installed in isolated env: $ENV_DIR\"\n",
        "echo \"Activate later with: source $ENV_DIR/bin/activate\"\n",
        "echo \"Log: $LOG\"\n",
        "#\n",
        "#Log: /content/_install_logs/fairseq_env_install.log\n",
        "#/content/_fairseq_env/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:295: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
        "#  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
        "# –ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç –∏ —á—Ç–æ –¥–µ–ª–∞—Ç—å\n",
        "#\n",
        "# –ï—Å–ª–∏ –∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å –∑–∞—Ö–æ—á–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è fairseq –≤ —ç—Ç–æ–º env:\n",
        "#\n",
        "# –ë—ã—Å—Ç—Ä—ã–π —Ñ–∏–∫—Å, —á—Ç–æ–±—ã –Ω–µ —Å—ã–ø–∞–ª–∏—Å—å –≤–æ—Ä–Ω–∏–Ω–≥–∏: –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å env –∏ –¥–æ–±–∞–≤–∏—Ç—å NumPy:\n",
        "#\n",
        "# source /content/_fairseq_env/bin/activate\n",
        "# python -m pip install -q \"numpy<2\"\n",
        "#\n",
        "# –û—à–∏–±–∫–∞ hydra/fairseq –Ω–∞ Py3.12 ‚Äî —ç—Ç–æ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π. –†–∞–±–æ—á–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã, –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω–æ –Ω—É–∂–µ–Ω fairseq:\n",
        "#\n",
        "# –ó–∞–ø—É—Å–∫–∞—Ç—å fairseq CLI –±–µ–∑ –∏–º–ø–æ—Ä—Ç–∞ –≥–∏–¥—Ä—ã (—Ä–µ–¥–∫–æ –ø–æ–º–æ–≥–∞–µ—Ç).\n",
        "#\n",
        "# –õ–∏–±–æ –¥–µ–ª–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π venv –ø–æ–¥ Python 3.10 –∏ —Å—Ç–∞–≤–∏—Ç—å —Ç—É–¥–∞ fairseq==0.12.2, hydra-core==1.0.7, omegaconf==2.0.6. (–≠—Ç–æ —É–∂–µ –æ—Ç–¥–µ–ª—å–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî –º–æ–≥—É –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —è—á–µ–π–∫—É –ø–æ–∑–∂–µ.)\n",
        "#\n",
        "\n"
      ],
      "metadata": {
        "id": "W7L9jXs50xnb",
        "outputId": "039f2d3b-ac93-4e53-cade-1ba91440c6d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title N09L ‚Ä¢ Light deps (CPU-first) + mini report\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# ACCEL (cpu/gpu); –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é cpu\n",
        "source /content/soni_accel.env 2>/dev/null || true\n",
        ": \"${ACCEL:=cpu}\"\n",
        "echo \"ACCEL=$ACCEL\"\n",
        "\n",
        "# system ffmpeg —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç\n",
        "if ! command -v ffmpeg >/dev/null 2>&1; then\n",
        "  sudo apt-get -y -qq update >/dev/null 2>&1 || true\n",
        "  sudo apt-get -y -qq install ffmpeg >/dev/null 2>&1 || true\n",
        "fi\n",
        "\n",
        "# pip –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
        "export PIP_PREFER_BINARY=1\n",
        "export PIP_DISABLE_PIP_VERSION_CHECK=1\n",
        "export PIP_USE_PEP517=1\n",
        "\n",
        "# —É–≤–∞–∂–∞–µ–º constraints, –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "CFILE=\"/content/constraints_sonitranslate.txt\"\n",
        "CARG=()\n",
        "[[ -s \"$CFILE\" ]] && CARG=(--constraint \"$CFILE\")\n",
        "\n",
        "# –ª—ë–≥–∫–∏–µ –ø–∞–∫–µ—Ç—ã + faiss –ø–æ –≤–∏–ª–∫–µ\n",
        "COMMON_PKGS=(rarfile srt ffmpeg-python praat-parselmouth pyworld torchcrepe librosa soundfile audioread)\n",
        "if [[ \"$ACCEL\" == \"gpu\" ]]; then\n",
        "  FAISS_PKG=\"faiss-gpu\"\n",
        "else\n",
        "  FAISS_PKG=\"faiss-cpu\"\n",
        "fi\n",
        "\n",
        "echo \"pip install: ${COMMON_PKGS[*]} $FAISS_PKG\"\n",
        "uv run python -m pip install -q \"${COMMON_PKGS[@]}\" \"$FAISS_PKG\" \"${CARG[@]}\"\n",
        "\n",
        "# –º–∏–Ω–∏-–æ—Ç—á—ë—Ç ok/FAIL (–∑–∞–≤–µ—Ä—à–∏—Ç —è—á–µ–π–∫—É —Å –æ—à–∏–±–∫–æ–π, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ –≤—Å—Ç–∞–ª–æ)\n",
        "python - <<'PY'\n",
        "import importlib, shutil, subprocess\n",
        "def line(n, ok, info=\"\"): print(f\"{n:18s}: {'ok' if ok else 'FAIL'}{(' '+info) if info else ''}\")\n",
        "\n",
        "ff = shutil.which(\"ffmpeg\")\n",
        "if ff:\n",
        "    try: ver = subprocess.check_output([ff,\"-version\"], text=True).splitlines()[0]\n",
        "    except Exception as e: ver=f\"ERR({e})\"\n",
        "    line(\"ffmpeg(system)\", True, f\"({ver})\")\n",
        "else:\n",
        "    line(\"ffmpeg(system)\", False)\n",
        "\n",
        "targets=[(\"rarfile\",\"rarfile\"),(\"srt\",\"srt\"),(\"ffmpeg\",\"ffmpeg-python\"),\n",
        "         (\"parselmouth\",\"praat-parselmouth\"),(\"pyworld\",\"pyworld\"),\n",
        "         (\"torchcrepe\",\"torchcrepe\"),(\"librosa\",\"librosa\"),\n",
        "         (\"soundfile\",\"soundfile\"),(\"audioread\",\"audioread\"),(\"faiss\",\"faiss\")]\n",
        "missing=0\n",
        "for mod, disp in targets:\n",
        "    try:\n",
        "        m=importlib.import_module(mod)\n",
        "        v=getattr(m,\"__version__\",\"?\")\n",
        "        line(disp, True, f\"(v {v})\")\n",
        "    except Exception as e:\n",
        "        line(disp, False, f\"({e})\"); missing=1\n",
        "raise SystemExit(missing)\n",
        "PY\n"
      ],
      "metadata": {
        "id": "lwO8IZa6uqhw",
        "outputId": "0529b9b3-9d53-4b47-ec05-720008aba91f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title N09G ‚Ä¢ GPU-light deps (auto-skip on CPU) + verify\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# —á–∏—Ç–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å —É—Å–∫–æ—Ä–µ–Ω–∏—è (ACCEL=cpu|gpu)\n",
        "source /content/soni_accel.env 2>/dev/null || true\n",
        ": \"${ACCEL:=cpu}\"\n",
        "\n",
        "if [[ \"$ACCEL\" != \"gpu\" ]]; then\n",
        "  echo \"[skip] ACCEL=$ACCEL ‚Üí GPU-light —à–∞–≥ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è\"\n",
        "  exit 0\n",
        "fi\n",
        "echo \"ACCEL=$ACCEL ‚Üí —Å—Ç–∞–≤–∏–º GPU-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\"\n",
        "\n",
        "# —É–≤–∞–∂–∞—Ç—å constraints (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
        "CFILE=\"/content/constraints_sonitranslate.txt\"\n",
        "CARG=()\n",
        "[[ -s \"$CFILE\" ]] && CARG=(--constraint \"$CFILE\")\n",
        "\n",
        "# –æ–±—â–∏–µ pip-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
        "export PIP_PREFER_BINARY=1\n",
        "export PIP_DISABLE_PIP_VERSION_CHECK=1\n",
        "export PIP_USE_PEP517=1\n",
        "\n",
        "# 1) onnxruntime-gpu –∏ faiss-gpu\n",
        "echo \"pip install: onnxruntime-gpu faiss-gpu\"\n",
        "uv run python -m pip install -q onnxruntime-gpu faiss-gpu \"${CARG[@]}\" || true\n",
        "\n",
        "# 2) –º–∏–Ω–∏-–≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è GPU-—Å—Ç–µ–∫–∞ (–∂—ë—Å—Ç–∫–∏–π fail –ø—Ä–∏ –∫—Ä–∏—Ç–∏–∫–µ)\n",
        "python - <<'PY'\n",
        "import sys, json\n",
        "\n",
        "def line(n, ok, extra=\"\"):\n",
        "    print(f\"{n:16s}: {'ok' if ok else 'FAIL'}{(' '+extra) if extra else ''}\")\n",
        "\n",
        "fail = False\n",
        "\n",
        "# torch + CUDA\n",
        "try:\n",
        "    import torch\n",
        "    cuda_ok = bool(torch.cuda.is_available())\n",
        "    info = f\"(v {torch.__version__}; cuda_available={cuda_ok})\"\n",
        "    line(\"torch\", True, info)\n",
        "    if not cuda_ok:\n",
        "        print(\"HINT: CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å 'GPU' runtime –≤ Colab –∏–ª–∏ –ø–æ—Å—Ç–∞–≤—å ACCEL=cpu.\")\n",
        "        fail = True\n",
        "except Exception as e:\n",
        "    line(\"torch\", False, f\"({e})\"); fail = True\n",
        "\n",
        "# onnxruntime providers\n",
        "try:\n",
        "    import onnxruntime as ort\n",
        "    prov = ort.get_available_providers()\n",
        "    line(\"onnxruntime\", True, f\"(providers={','.join(prov)})\")\n",
        "    if \"CUDAExecutionProvider\" not in prov:\n",
        "        print(\"HINT: –ù–µ—Ç CUDAExecutionProvider –≤ onnxruntime ‚Äî –ø—Ä–æ–≤–µ—Ä—å CUDA/–¥—Ä–∞–π–≤–µ—Ä/–≤–µ—Ä—Å–∏—é onnxruntime-gpu.\")\n",
        "        fail = True\n",
        "except Exception as e:\n",
        "    line(\"onnxruntime\", False, f\"({e})\"); fail = True\n",
        "\n",
        "# faiss gpu\n",
        "try:\n",
        "    import faiss\n",
        "    ng = getattr(faiss, \"get_num_gpus\", lambda: None)()\n",
        "    if ng is None:\n",
        "        # –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –µ—Å—Ç—å, –Ω–æ –±–µ–∑ GPU-—Ö—É–∫–æ–≤\n",
        "        line(\"faiss\", True, \"(num_gpus=unknown)\")\n",
        "    else:\n",
        "        line(\"faiss\", True, f\"(num_gpus={ng})\")\n",
        "        if isinstance(ng, int) and ng < 1:\n",
        "            print(\"HINT: faiss –≤–∏–¥–∏—Ç 0 GPU. –£–±–µ–¥–∏—Å—å, —á—Ç–æ –≤—ã–±—Ä–∞–Ω GPU-—Ä–∞–Ω—Ç–∞–π–º.\")\n",
        "            fail = True\n",
        "except Exception as e:\n",
        "    line(\"faiss\", False, f\"({e})\"); fail = True\n",
        "\n",
        "if fail:\n",
        "    sys.exit(1)\n",
        "PY\n",
        "\n",
        "# –ï—Å–ª–∏ ACCEL=cpu ‚Üí —ç—Ç–∞ —è—á–µ–π–∫–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç (–ø–µ—á–∞—Ç–∞–µ—Ç [skip]).\n",
        "# –ï—Å–ª–∏ ACCEL=gpu ‚Üí —Å—Ç–∞–≤–∏—Ç onnxruntime-gpu –∏ faiss-gpu, –∑–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ—Ç torch.cuda, –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã ORT –∏ –Ω–∞–ª–∏—á–∏–µ GPU –≤ faiss.\n",
        "# –û—à–∏–±–∫–∞ —à–∞–≥–∞ = —á—ë—Ç–∫–∏–π —Å–∏–≥–Ω–∞–ª ¬´–Ω–µ –≥–æ—Ç–æ–≤–æ –∫ GPU-–ø—Ä–æ–≥–æ–Ω—É¬ª.\n"
      ],
      "metadata": {
        "id": "eQEUtBO2ynQ7",
        "outputId": "9b7fee2a-baae-43be-8235-51c411ed77e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [N09M-HOTFIX] Fix NumPy ABI for torchcrepe/torchvision (CPU)\n",
        "# - Pins: numpy<2.0 (1.26.4), torchvision==0.20.1+cpu\n",
        "# - Reinstalls torchvision/torchcrepe cleanly\n",
        "# - Updates constraints_sonitranslate.txt\n",
        "# - Restarts runtime (set NO_RESTART=\"1\" to skip)\n",
        "\n",
        "import os, sys, subprocess, json, re, textwrap, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def sh(cmd):\n",
        "    print(f\"$ {cmd}\")\n",
        "    return subprocess.run(cmd, shell=True, check=True, text=True)\n",
        "\n",
        "CONSTRAINTS = Path(\"/content/constraints_sonitranslate.txt\")\n",
        "CONSTRAINTS.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Pin NumPy<2 globally\n",
        "sh(\"python -m pip install -q --upgrade --force-reinstall 'numpy<2,>=1.26.0'\")\n",
        "\n",
        "# 2) Clean reinstall torchvision matching torch 2.5.1 (CPU wheel)\n",
        "#    Torch —É–∂–µ —Å—Ç–æ–∏—Ç (2.5.1+cpu). –ü–æ–¥ –Ω–µ–≥–æ ‚Äî torchvision 0.20.1.\n",
        "sh(\"python -m pip uninstall -y torchvision || true\")\n",
        "sh(\"python -m pip install -q --no-cache-dir --index-url https://download.pytorch.org/whl/cpu torchvision==0.20.1\")\n",
        "\n",
        "# 3) Clean reinstall torchcrepe (–ø–æ–¥ –Ω–æ–≤—ã–π NumPy ABI)\n",
        "sh(\"python -m pip uninstall -y torchcrepe || true\")\n",
        "sh(\"python -m pip install -q --no-cache-dir torchcrepe\")\n",
        "\n",
        "# 4) Sanity print\n",
        "sh(\"python - << 'PY'\\nimport numpy, torch\\nprint('numpy:', numpy.__version__)\\nprint('torch :', torch.__version__)\\nPY\")\n",
        "\n",
        "# 5) Update constraints file: ensure pins are present\n",
        "pins = {\n",
        "    \"numpy\": \"numpy<2\",\n",
        "    \"torchvision\": \"torchvision==0.20.1\",\n",
        "}\n",
        "existing = {}\n",
        "if CONSTRAINTS.exists():\n",
        "    lines = CONSTRAINTS.read_text().splitlines()\n",
        "else:\n",
        "    lines = []\n",
        "\n",
        "out_lines = []\n",
        "found = set()\n",
        "for line in lines:\n",
        "    m = re.match(r\"^\\s*([A-Za-z0-9_.\\-]+)\\s*([<>=!~!]+)\\s*([^\\s#]+)\", line)\n",
        "    if m:\n",
        "        name = m.group(1).lower()\n",
        "        existing[name] = line\n",
        "        if name in pins:\n",
        "            # overwrite with our pin once (skip old)\n",
        "            continue\n",
        "    out_lines.append(line)\n",
        "\n",
        "# append our pins (idempotent)\n",
        "for name, rule in pins.items():\n",
        "    out_lines.append(rule)\n",
        "\n",
        "CONSTRAINTS.write_text(\"\\n\".join([l for l in out_lines if l.strip()]) + \"\\n\")\n",
        "\n",
        "print(\"\\n[ok] constraints_sonitranslate.txt updated with:\")\n",
        "for _, rule in pins.items():\n",
        "    print(\"  -\", rule)\n",
        "\n",
        "# 6) Optional runtime restart (safer for C-ABI switches)\n",
        "if os.getenv(\"NO_RESTART\",\"0\") != \"1\":\n",
        "    print(\"\\n[info] Restarting runtime to finalize ABI switch...\")\n",
        "    # Hard-exit ‚Äî Colab –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç —Å—Ä–µ–¥—É\n",
        "    import os; os._exit(0)\n",
        "else:\n",
        "    print(\"\\n[skip] Restart disabled (NO_RESTART=1). Please restart runtime manually.\")\n"
      ],
      "metadata": {
        "id": "dHe1owCUZiGT",
        "outputId": "5cb8b68e-3a35-4282-b534-7ee90f6cbe13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [N09M-VERIFY] Quick import check after ABI fix\n",
        "import numpy, torch\n",
        "print(\"numpy      :\", numpy.__version__)\n",
        "print(\"torch      :\", torch.__version__)\n",
        "\n",
        "# torchvision & torchcrepe imports\n",
        "try:\n",
        "    import torchvision\n",
        "    print(\"torchvision:\", torchvision.__version__)\n",
        "except Exception as e:\n",
        "    print(\"torchvision import FAIL:\", e)\n",
        "\n",
        "try:\n",
        "    import torchcrepe\n",
        "    print(\"torchcrepe :\", getattr(torchcrepe, '__version__', 'unknown'))\n",
        "except Exception as e:\n",
        "    print(\"torchcrepe import FAIL:\", e)\n"
      ],
      "metadata": {
        "id": "DmkfNeMVZmDL",
        "outputId": "1f96b624-00e3-498f-b71c-aaa95ab2ddf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title N09M ‚Ä¢ MOCK test (imports + tiny ops; no downloads)\n",
        "import os, sys, shutil, subprocess, importlib\n",
        "\n",
        "# --- ACCEL (cpu/gpu) ---\n",
        "ACCEL = \"cpu\"\n",
        "envp = \"/content/soni_accel.env\"\n",
        "if os.path.exists(envp):\n",
        "    for ln in open(envp, \"r\", encoding=\"utf-8\"):\n",
        "        if ln.startswith(\"export ACCEL=\"):\n",
        "            ACCEL = ln.split(\"=\",1)[1].strip().strip('\"'); break\n",
        "print(\"ACCEL:\", ACCEL)\n",
        "\n",
        "def line(name, ok, extra=\"\"):\n",
        "    print(f\"{name:18s}: {'ok' if ok else 'FAIL'}{(' ' + extra) if extra else ''}\")\n",
        "\n",
        "failed = False\n",
        "\n",
        "# --- system ffmpeg ---\n",
        "ff = shutil.which(\"ffmpeg\")\n",
        "if ff:\n",
        "    try:\n",
        "        ver = subprocess.check_output([ff,\"-version\"], text=True).splitlines()[0]\n",
        "    except Exception as e:\n",
        "        ver = f\"ERR({e})\"\n",
        "    line(\"ffmpeg(system)\", True, f\"({ver})\")\n",
        "else:\n",
        "    line(\"ffmpeg(system)\", False)\n",
        "    failed = True\n",
        "\n",
        "# --- light deps imports (–∏–∑ N09L) ---\n",
        "LIGHT = [\n",
        "    (\"rarfile\",\"rarfile\"),\n",
        "    (\"srt\",\"srt\"),\n",
        "    (\"ffmpeg\",\"ffmpeg-python\"),\n",
        "    (\"parselmouth\",\"praat-parselmouth\"),\n",
        "    (\"pyworld\",\"pyworld\"),\n",
        "    (\"torchcrepe\",\"torchcrepe\"),\n",
        "    (\"librosa\",\"librosa\"),\n",
        "    (\"soundfile\",\"soundfile\"),\n",
        "    (\"audioread\",\"audioread\"),\n",
        "    (\"faiss\",\"faiss\"),\n",
        "]\n",
        "for mod, disp in LIGHT:\n",
        "    try:\n",
        "        m = importlib.import_module(mod)\n",
        "        v = getattr(m, \"__version__\", \"?\")\n",
        "        line(disp, True, f\"(v {v})\")\n",
        "    except Exception as e:\n",
        "        line(disp, False, f\"({e})\")\n",
        "        failed = True\n",
        "\n",
        "# --- torch quick op (CPU/GPU) ---\n",
        "try:\n",
        "    import torch\n",
        "    info = f\"(v {torch.__version__}; cuda={torch.cuda.is_available()})\"\n",
        "    if torch.cuda.is_available():\n",
        "        a = torch.randn(64,64, device=\"cuda\")\n",
        "        b = torch.randn(64,64, device=\"cuda\")\n",
        "        _ = (a @ b)[0,0].item()\n",
        "        info += \"; matmul_cuda ok\"\n",
        "    else:\n",
        "        a = torch.randn(64,64)\n",
        "        b = torch.randn(64,64)\n",
        "        _ = (a @ b)[0,0].item()\n",
        "        info += \"; matmul_cpu ok\"\n",
        "    line(\"torch\", True, info)\n",
        "except Exception as e:\n",
        "    line(\"torch\", False, f\"({e})\")\n",
        "    failed = True\n",
        "\n",
        "# --- torchvision / torchaudio (import only) ---\n",
        "for mod in [\"torchvision\",\"torchaudio\"]:\n",
        "    try:\n",
        "        m = importlib.import_module(mod)\n",
        "        v = getattr(m, \"__version__\", \"?\")\n",
        "        line(mod, True, f\"(v {v})\")\n",
        "    except Exception as e:\n",
        "        # –Ω–µ –≤—Å–µ–≥–¥–∞ –∫—Ä–∏—Ç–∏—á–Ω–æ, –Ω–æ –ø–æ–¥—Å–≤–µ—Ç–∏–º\n",
        "        line(mod, False, f\"({e})\")\n",
        "\n",
        "# --- onnxruntime providers (GPU –≤–∞–∂–Ω–µ–µ) ---\n",
        "try:\n",
        "    import onnxruntime as ort\n",
        "    providers = ort.get_available_providers()\n",
        "    line(\"onnxruntime\", True, f\"(providers={','.join(providers)})\")\n",
        "    if ACCEL == \"gpu\" and \"CUDAExecutionProvider\" not in providers:\n",
        "        print(\"WARN: ACCEL=gpu, –Ω–æ CUDAExecutionProvider –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ onnxruntime\")\n",
        "except Exception as e:\n",
        "    line(\"onnxruntime\", False, f\"({e})\")\n",
        "    if ACCEL == \"gpu\":\n",
        "        failed = True\n",
        "\n",
        "if failed:\n",
        "    raise SystemExit(1)\n"
      ],
      "metadata": {
        "id": "EFDu2dD_0YZG",
        "outputId": "54792bad-9ae4-48bf-8395-2b27ce99f55d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [N10-FIX] sox + constraints sync + light deps\n",
        "# MODE: \"align_to_env\" -> –ø—Ä–∞–≤–∏–º constraints –ø–æ–¥ —Ç–µ–∫—É—â–µ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)\n",
        "#       \"align_env_to_constraints\" -> –¥–∞—É–Ω–≥—Ä–µ–π–¥–∏–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ –ø–æ–¥ constraints\n",
        "MODE = \"align_to_env\"  # \"align_to_env\" | \"align_env_to_constraints\"\n",
        "\n",
        "import subprocess, re\n",
        "from pathlib import Path\n",
        "\n",
        "def sh(cmd, check=True):\n",
        "    print(\"$\", cmd)\n",
        "    return subprocess.run(cmd, shell=True, check=check, text=True)\n",
        "\n",
        "# 0) sox (—Ç—Ä–µ–±—É–µ—Ç—Å—è –≤ strict)\n",
        "try:\n",
        "    sh(\"apt-get update -qq\")\n",
        "    sh(\"apt-get install -y -qq sox libsox-fmt-all\")\n",
        "except Exception as e:\n",
        "    print(\"[warn] apt install sox failed:\", e)\n",
        "\n",
        "# 1) ¬´–ª–µ–≥–∫–∏–µ¬ª –ø–∞–∫–µ—Ç—ã (–±—ã–ª–∏ hints, –Ω–µ —Ñ–∞—Ç–∞–ª—å–Ω–æ, –Ω–æ –ø–æ—Å—Ç–∞–≤–∏–º)\n",
        "sh(\"python -m pip install -q ffmpeg-python praat-parselmouth\")\n",
        "\n",
        "# 2) –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è constraints vs –æ–∫—Ä—É–∂–µ–Ω–∏–µ\n",
        "CFILE = Path(\"/content/constraints_sonitranslate.txt\")\n",
        "CFILE.parent.mkdir(parents=True, exist_ok=True)\n",
        "if not CFILE.exists():\n",
        "    CFILE.write_text(\"\", encoding=\"utf-8\")\n",
        "\n",
        "def get_installed(pkg):\n",
        "    import importlib.metadata as im\n",
        "    try:\n",
        "        return im.version(pkg)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def replace_or_append(lines, name, rule_line):\n",
        "    # —É–¥–∞–ª–∏–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è name –∏ –¥–æ–±–∞–≤–∏–º –Ω–∞—à—É\n",
        "    out = []\n",
        "    pat = re.compile(rf\"^\\s*{re.escape(name)}\\s*[<>=!~]+\")\n",
        "    for ln in lines:\n",
        "        if pat.match(ln):\n",
        "            continue\n",
        "        out.append(ln)\n",
        "    out.append(rule_line)\n",
        "    return out\n",
        "\n",
        "lines = [ln for ln in CFILE.read_text().splitlines() if ln.strip()]\n",
        "\n",
        "opencv_inst = get_installed(\"opencv-python\")\n",
        "torchvision_inst = get_installed(\"torchvision\")\n",
        "\n",
        "if MODE == \"align_to_env\":\n",
        "    # –ü—Ä–∏–Ω–∏–º–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ—Ä—Å–∏–∏:\n",
        "    # - opencv-python -> —Ä–æ–≤–Ω–æ —Ç–µ–∫—É—â—É—é (–∏–ª–∏ –∑–∞–¥–∞–π –∫–æ—Ä–∏–¥–æ—Ä, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å)\n",
        "    if opencv_inst:\n",
        "        lines = replace_or_append(lines, \"opencv-python\", f\"opencv-python=={opencv_inst}\")\n",
        "    # - torchvision -> ¬´—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è¬ª –≤–∏–ª–æ—á–∫–∞, —á—Ç–æ–±—ã –ø—Ä–∏–Ω–∏–º–∞—Ç—å +cpu (local version)\n",
        "    #   –ò—Å–ø–æ–ª—å–∑—É–µ–º ~=0.20.1 (—Ä–∞–∑—Ä–µ—à–∏—Ç 0.20.x –∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ —Å—É—Ñ—Ñ–∏–∫—Å—ã)\n",
        "    lines = replace_or_append(lines, \"torchvision\", \"torchvision~=0.20.1\")\n",
        "\n",
        "elif MODE == \"align_env_to_constraints\":\n",
        "    # –ß–∏—Ç–∞–µ–º —Ü–µ–ª–µ–≤—É—é –≤–µ—Ä—Å–∏—é –∏–∑ constraints\n",
        "    target_cv = None\n",
        "    for ln in lines:\n",
        "        m = re.match(r\"^\\s*opencv-python\\s*==\\s*([^\\s#]+)\", ln)\n",
        "        if m:\n",
        "            target_cv = m.group(1).strip()\n",
        "            break\n",
        "    if target_cv:\n",
        "        # –°—Ç–∞–≤–∏–º –∏–º–µ–Ω–Ω–æ –µ—ë\n",
        "        sh(f\"python -m pip install -q --force-reinstall opencv-python=={target_cv}\")\n",
        "    # torchvision: —Å—Ç–∞–≤–∏–º —Å—Ç—Ä–æ–≥–æ 0.20.1 —Å PyTorch CPU index (–¥–∞–∂–µ –µ—Å–ª–∏ —É–∂–µ 0.20.1+cpu)\n",
        "    sh(\"python -m pip install -q --no-cache-dir --index-url https://download.pytorch.org/whl/cpu torchvision==0.20.1\")\n",
        "\n",
        "# 3) –°–æ—Ö—Ä–∞–Ω—è–µ–º constraints\n",
        "CFILE.write_text(\"\\n\".join(l for l in lines if l.strip()) + \"\\n\", encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n[ok] Constraints saved to:\", CFILE)\n",
        "print(CFILE.read_text())\n",
        "print(\"\\n–¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å—Ç–∏ N10 –∑–∞–Ω–æ–≤–æ (strict).\")\n"
      ],
      "metadata": {
        "id": "EvMw5brbfpYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [N10] REPORT ‚Äî —Å—Ä–µ–¥–∞ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (—Å –≤—ã–±–æ—Ä–æ–º —É—Ä–æ–≤–Ω—è –ø—Ä–æ–≤–µ—Ä–∫–∏)\n",
        "#@markdown **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** —Å–æ–±—Ä–∞—Ç—å —Ä–∞—Å—à–∏—Ä—ë–Ω–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ –æ–∫—Ä—É–∂–µ–Ω–∏—é (Python/torch/FAISS/ONNX/binaries/¬´–ª—ë–≥–∫–∏–µ¬ª deps),\n",
        "#@markdown —Å—Ä–∞–≤–Ω–∏—Ç—å —Å constraints –∏ –≤—ã–¥–∞—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫–∏/—Å–±–æ–∏. –ù–∏—á–µ–≥–æ –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç.\n",
        "#@markdown\n",
        "#@markdown **–£—Ä–æ–≤–Ω–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ (ENFORCE):**\n",
        "#@markdown - `none` ‚Äî —Ç–æ–ª—å–∫–æ –æ—Ç—á—ë—Ç –∏ –ø–æ–¥—Å–∫–∞–∑–∫–∏. –õ—é–±—ã–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è ‚âà –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è.\n",
        "#@markdown - `soft` ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ–µ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ (torch/cuda –ø—Ä–∏ ACCEL=gpu, onnxruntime –±–µ–∑ GPU-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞,\n",
        "#@markdown   FAISS –≤ –Ω–µ–≤–µ—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ) ‚Üí –æ—à–∏–±–æ—á–Ω—ã–π –∫–æ–¥ **2**. –û—Å—Ç–∞–ª—å–Ω–æ–µ = –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è.\n",
        "#@markdown - `strict` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) ‚Äî –≤—Å—ë –∏–∑ *soft* **–ø–ª—é—Å**: –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è constraints –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–µ–≤—ã—Ö\n",
        "#@markdown   –±–∏–Ω–∞—Ä–Ω–∏–∫–æ–≤ (ffmpeg, sox) —Å—á–∏—Ç–∞—é—Ç—Å—è –æ—à–∏–±–∫–∞–º–∏ ‚Üí –∫–æ–¥ **1**.\n",
        "ENFORCE = \"strict\" #@param [\"strict\", \"soft\", \"none\"] {type:\"string\"}\n",
        "\n",
        "import os, sys, json, shutil, subprocess, datetime, platform, re\n",
        "from pathlib import Path\n",
        "\n",
        "TS = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUT_DIR = Path(\"/content/_reports\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ACCEL = (os.getenv(\"ACCEL\") or os.getenv(\"ACCELERATE\") or \"cpu\").strip().lower()\n",
        "\n",
        "def sh(cmd):\n",
        "    try:\n",
        "        out = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT, text=True, timeout=20)\n",
        "        return 0, out.strip()\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        return e.returncode, e.output.strip()\n",
        "    except Exception as e:\n",
        "        return 1, f\"ERROR: {e}\"\n",
        "\n",
        "def pkg_ver(name):\n",
        "    try:\n",
        "        import importlib.metadata as im\n",
        "    except Exception:\n",
        "        import importlib_metadata as im\n",
        "    try:\n",
        "        return im.version(name)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def try_import(name, attr=None):\n",
        "    try:\n",
        "        mod = __import__(name, fromlist=['*'])\n",
        "        if attr:\n",
        "            return hasattr(mod, attr), f\"hasattr({attr})={hasattr(mod, attr)}\"\n",
        "        return True, \"ok\"\n",
        "    except Exception as e:\n",
        "        return False, f\"{type(e).__name__}: {e}\"\n",
        "\n",
        "def torch_info():\n",
        "    info = {\"installed\": False}\n",
        "    try:\n",
        "        import torch\n",
        "        info[\"installed\"] = True\n",
        "        info[\"version\"] = torch.__version__\n",
        "        info[\"cuda_available\"] = torch.cuda.is_available()\n",
        "        info[\"cuda_device_count\"] = torch.cuda.device_count() if info[\"cuda_available\"] else 0\n",
        "        info[\"cuda_version\"] = getattr(torch.version, \"cuda\", None)\n",
        "        info[\"cudnn_version\"] = getattr(torch.backends.cudnn, \"version\", lambda: None)()\n",
        "        info[\"mps_available\"] = getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available()\n",
        "    except Exception as e:\n",
        "        info[\"error\"] = f\"{type(e).__name__}: {e}\"\n",
        "    return info\n",
        "\n",
        "def faiss_info():\n",
        "    r = {\"installed\": False}\n",
        "    try:\n",
        "        import faiss\n",
        "        r[\"installed\"] = True\n",
        "        r[\"has_gpu\"] = hasattr(faiss, \"StandardGpuResources\")\n",
        "        r[\"version\"] = getattr(faiss, \"__version__\", None)\n",
        "    except Exception as e:\n",
        "        r[\"error\"] = f\"{type(e).__name__}: {e}\"\n",
        "    return r\n",
        "\n",
        "def onnx_info():\n",
        "    r = {\"runtime_cpu\": None, \"runtime_gpu\": None}\n",
        "    ok, _ = try_import(\"onnxruntime\")\n",
        "    r[\"runtime_cpu\"] = ok\n",
        "    if ok:\n",
        "        try:\n",
        "            import onnxruntime as ort\n",
        "            r[\"providers\"] = ort.get_available_providers()\n",
        "            r[\"runtime_gpu\"] = any(\"CUDA\" in p or \"ROCM\" in p for p in r[\"providers\"])\n",
        "        except Exception as e:\n",
        "            r[\"providers_error\"] = f\"{type(e).__name__}: {e}\"\n",
        "    return r\n",
        "\n",
        "def which(name):\n",
        "    p = shutil.which(name); return p or \"\"\n",
        "\n",
        "BIN_CHECKS = [\"ffmpeg\", \"ffprobe\", \"sox\"]\n",
        "LIGHT_PKGS = [\"rarfile\",\"srt\",\"ffmpeg-python\",\"praat-parselmouth\",\"pyworld\",\"torchcrepe\",\"librosa\",\"soundfile\",\"audioread\"]\n",
        "KEY_PKGS   = [\"numpy\",\"scipy\",\"torch\",\"torchvision\",\"torchaudio\",\"omegaconf\",\"hydra-core\",\"fairseq\",\"tqdm\"]\n",
        "GPU_PKGS   = [\"onnxruntime-gpu\",\"xformers\",\"triton\"]\n",
        "FAISS_FLAVORS = [\"faiss-cpu\",\"faiss-gpu\",\"faiss\"]\n",
        "\n",
        "def parse_constraints(path=\"/content/constraints_sonitranslate.txt\"):\n",
        "    d = {}; p = Path(path)\n",
        "    if not p.exists(): return d\n",
        "    for line in p.read_text().splitlines():\n",
        "        line=line.strip()\n",
        "        if not line or line.startswith(\"#\"): continue\n",
        "        m = re.match(r\"([A-Za-z0-9_.\\-]+)\\s*([<>=!~]+)\\s*([^\\s#]+)\", line)\n",
        "        if m:\n",
        "            name, op, ver = m.groups()\n",
        "            d[name.lower()] = {\"op\": op, \"ver\": ver, \"raw\": line}\n",
        "    return d\n",
        "\n",
        "def version_satisfies(installed, op, target):\n",
        "    from packaging.version import Version, InvalidVersion\n",
        "    try:\n",
        "        iv = Version(installed); tv = Version(target.replace(\"*\",\"0\"))\n",
        "    except InvalidVersion:\n",
        "        return None\n",
        "    return {\n",
        "        \"==\": iv==tv, \">=\": iv>=tv, \"<=\": iv<=tv, \">\": iv>tv, \"<\": iv<tv,\n",
        "        \"!=\": iv!=tv, \"<>\": iv!=tv, \"~=\": (iv.major==tv.major and iv>=tv),\n",
        "    }.get(op, None)\n",
        "\n",
        "# ---------- Build report ----------\n",
        "report = {\n",
        "    \"meta\": {\"timestamp\": TS, \"platform\": platform.platform(), \"python\": sys.version.replace(\"\\n\",\" \"),\n",
        "             \"accelerator_profile\": ACCEL, \"enforce\": ENFORCE},\n",
        "    \"bins\": {}, \"torch\": torch_info(), \"faiss\": faiss_info(), \"onnx\": onnx_info(),\n",
        "    \"packages\": {}, \"light_packages\": {}, \"gpu_packages\": {}, \"faiss_flavors\": {},\n",
        "    \"constraints\": {\"path\": \"/content/constraints_sonitranslate.txt\", \"diff\": []},\n",
        "    \"hints\": [], \"failures\": []\n",
        "}\n",
        "\n",
        "for b in BIN_CHECKS:\n",
        "    p = which(b)\n",
        "    code, out = sh(f\"{b} -version\" if b==\"ffmpeg\" else f\"{b} --version\")\n",
        "    report[\"bins\"][b] = {\"path\": p, \"ok\": bool(p), \"version_head\": (out.splitlines()[0] if out else \"\")}\n",
        "\n",
        "for n in KEY_PKGS: report[\"packages\"][n] = pkg_ver(n)\n",
        "for n in LIGHT_PKGS:\n",
        "    v = pkg_ver(n); ok, msg = try_import(n)\n",
        "    report[\"light_packages\"][n] = {\"version\": v, \"import_ok\": ok, \"note\": msg}\n",
        "for n in GPU_PKGS: report[\"gpu_packages\"][n] = pkg_ver(n)\n",
        "for n in FAISS_FLAVORS: report[\"faiss_flavors\"][n] = {\"installed\": pkg_ver(n) is not None, \"version\": pkg_ver(n)}\n",
        "\n",
        "# constraints diff\n",
        "constraints = parse_constraints()\n",
        "if constraints:\n",
        "    for cname, rule in constraints.items():\n",
        "        inst = pkg_ver(cname); sat = None if inst is None else version_satisfies(inst, rule[\"op\"], rule[\"ver\"])\n",
        "        report[\"constraints\"][\"diff\"].append({\"package\": cname, \"installed\": inst, \"rule\": rule, \"satisfies\": sat})\n",
        "\n",
        "# ---------- Hints & Failure logic ----------\n",
        "t = report[\"torch\"]; fai = report[\"faiss\"]; onn = report[\"onnx\"]\n",
        "\n",
        "def add_fail(msg): report[\"failures\"].append(msg)\n",
        "def add_hint(msg): report[\"hints\"].append(msg)\n",
        "\n",
        "# Core torch\n",
        "if not t.get(\"installed\"):\n",
        "    add_fail(\"PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.\")\n",
        "\n",
        "# ACCEL-specific checks\n",
        "if ACCEL == \"gpu\":\n",
        "    if not t.get(\"cuda_available\"): add_fail(\"ACCEL=gpu, –Ω–æ torch.cuda.is_available()=False.\")\n",
        "    if not (onn.get(\"runtime_gpu\") or any(\"CUDA\" in p or \"ROCM\" in p for p in onn.get(\"providers\", []))):\n",
        "        add_fail(\"onnxruntime –±–µ–∑ GPU –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø—Ä–∏ ACCEL=gpu.\")\n",
        "    if not fai.get(\"installed\"):\n",
        "        add_fail(\"FAISS –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∏ ACCEL=gpu (–æ–∂–∏–¥–∞–µ—Ç—Å—è faiss-gpu).\")\n",
        "    elif not fai.get(\"has_gpu\"):\n",
        "        add_fail(\"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω FAISS –±–µ–∑ GPU API –ø—Ä–∏ ACCEL=gpu.\")\n",
        "else:\n",
        "    if t.get(\"cuda_available\"): add_hint(\"ACCEL=cpu, –Ω–æ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞ ‚Äî GPU –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è.\")\n",
        "\n",
        "# Light deps: warn if import fails (–Ω–µ —Ñ–µ–π–ª–∏–º –≤ soft/none)\n",
        "for n, meta in report[\"light_packages\"].items():\n",
        "    if not meta[\"import_ok\"]:\n",
        "        add_hint(f\"–ò–º–ø–æ—Ä—Ç –ø–∞–∫–µ—Ç–∞ {n} –Ω–µ —É–¥–∞–ª—Å—è: {meta['note']}\")\n",
        "\n",
        "# Binaries: –≤ strict ‚Äî —Å—á–∏—Ç–∞–µ–º –∫—Ä–∏—Ç–∏—á–Ω—ã–º–∏\n",
        "if ENFORCE == \"strict\":\n",
        "    for b in (\"ffmpeg\",\"sox\"):\n",
        "        if not report[\"bins\"][b][\"ok\"]:\n",
        "            add_fail(f\"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –±–∏–Ω–∞—Ä–Ω–∏–∫: {b}\")\n",
        "\n",
        "# Constraints ‚Üí –≤ strict —ç—Ç–æ –æ—à–∏–±–∫–∏\n",
        "unsatisfied = [d for d in report[\"constraints\"][\"diff\"] if d[\"satisfies\"] is False]\n",
        "if ENFORCE == \"strict\" and unsatisfied:\n",
        "    for d in unsatisfied:\n",
        "        add_fail(f\"Constraints: {d['package']} installed={d['installed']} rule={d['rule']['raw']} -> NOT SATISFIED\")\n",
        "\n",
        "# ---------- Save outputs ----------\n",
        "json_path = OUT_DIR / f\"N10_report_{TS}.json\"\n",
        "with open(json_path, \"w\") as f: json.dump(report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "def md_bool(b): return \"‚úÖ\" if b else \"‚ùå\"\n",
        "lines = []\n",
        "lines.append(f\"# N10 REPORT ‚Äî {TS}\")\n",
        "lines.append(f\"- Accelerator: **{ACCEL}**, Enforce: **{ENFORCE}**\")\n",
        "lines.append(f\"- Python: `{report['meta']['python']}`\")\n",
        "lines.append(f\"- Platform: `{report['meta']['platform']}`\\n\")\n",
        "lines.append(\"## Binaries\")\n",
        "for b, v in report[\"bins\"].items():\n",
        "    lines.append(f\"- **{b}**: {md_bool(v['ok'])} `{v['path']}` ‚Äî {v['version_head']}\")\n",
        "lines.append(\"\\n## Torch\")\n",
        "lines.append(f\"- installed: {md_bool(t.get('installed', False))}, version: `{t.get('version')}`\")\n",
        "lines.append(f\"- cuda_available: {md_bool(t.get('cuda_available', False))}, devices: {t.get('cuda_device_count',0)}, cuda: {t.get('cuda_version')}, cudnn: {t.get('cudnn_version')}\")\n",
        "lines.append(f\"- mps_available: {md_bool(t.get('mps_available', False))}\\n\")\n",
        "lines.append(\"## FAISS\")\n",
        "lines.append(f\"- installed: {md_bool(fai.get('installed', False))}, version: `{fai.get('version')}`, gpu_api: {md_bool(fai.get('has_gpu', False))}\")\n",
        "lines.append(\"### FAISS flavors\")\n",
        "for n, v in report[\"faiss_flavors\"].items():\n",
        "    lines.append(f\"- {n}: {md_bool(v['installed'])} {('`'+str(v['version'])+'`') if v['version'] else ''}\")\n",
        "lines.append(\"\\n## ONNX Runtime\")\n",
        "lines.append(f\"- cpu: {md_bool(onn.get('runtime_cpu', False))}, gpu: {md_bool(onn.get('runtime_gpu', False))}\")\n",
        "if \"providers\" in onn: lines.append(f\"- providers: {', '.join(onn['providers'])}\")\n",
        "lines.append(\"\\n## Key packages\")\n",
        "for n in KEY_PKGS:\n",
        "    lines.append(f\"- {n}: `{report['packages'].get(n)}`\")\n",
        "lines.append(\"\\n## Light deps (import check)\")\n",
        "for n, meta in report[\"light_packages\"].items():\n",
        "    lines.append(f\"- {n}: v=`{meta['version']}` import={md_bool(meta['import_ok'])} ({meta['note']})\")\n",
        "lines.append(\"\\n## GPU packages (presence)\")\n",
        "for n in GPU_PKGS:\n",
        "    lines.append(f\"- {n}: `{report['gpu_packages'].get(n)}`\")\n",
        "if report[\"constraints\"][\"diff\"]:\n",
        "    lines.append(\"\\n## Constraints diff\")\n",
        "    for d in report[\"constraints\"][\"diff\"]:\n",
        "        sat = d[\"satisfies\"]; emoji = \"‚úÖ\" if sat else (\"‚ö†Ô∏è\" if sat is not None else \"‚ùì\")\n",
        "        lines.append(f\"- {d['package']}: installed=`{d['installed']}` rule=`{d['rule']['raw']}` -> {emoji}\")\n",
        "if report[\"hints\"]:\n",
        "    lines.append(\"\\n## Hints\")\n",
        "    for h in report[\"hints\"]: lines.append(f\"- {h}\")\n",
        "if report[\"failures\"]:\n",
        "    lines.append(\"\\n## Failures\")\n",
        "    for h in report[\"failures\"]: lines.append(f\"- {h}\")\n",
        "\n",
        "md_path = OUT_DIR / f\"N10_report_{TS}.md\"\n",
        "md_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "print(\"== N10 REPORT COMPLETE ==\")\n",
        "print(f\"JSON: {json_path}\")\n",
        "print(f\"MD  : {md_path}\")\n",
        "print(\"\\n--- SUMMARY ---\")\n",
        "print(f\"ENFORCE={ENFORCE} | ACCEL={ACCEL}\")\n",
        "print(f\"Torch: {t.get('version')} | CUDA avail: {t.get('cuda_available')} | FAISS gpu_api: {fai.get('has_gpu')}\")\n",
        "print(f\"onnx providers: {', '.join(onn.get('providers', [])) if onn.get('providers') else 'n/a'}\")\n",
        "print(f\"ffmpeg in PATH: {md_bool(report['bins']['ffmpeg']['ok'])}\")\n",
        "if report[\"hints\"]:\n",
        "    print(\"HINTS:\"); [print(f\"- {h}\") for h in report[\"hints\"]]\n",
        "if report[\"failures\"]:\n",
        "    print(\"FAILURES:\"); [print(f\"- {h}\") for h in report[\"failures\"]]\n",
        "\n",
        "# --- Exit codes by ENFORCE ---\n",
        "if ENFORCE == \"none\":\n",
        "    pass\n",
        "elif ENFORCE == \"soft\":\n",
        "    if report[\"failures\"]:\n",
        "        sys.exit(2)  # soft fail for CI\n",
        "elif ENFORCE == \"strict\":\n",
        "    if report[\"failures\"]:\n",
        "        sys.exit(1)\n"
      ],
      "metadata": {
        "id": "LYNMCOTUXTY5",
        "outputId": "aac9b57c-be9f-47a9-e569-d9f35884556b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title STEP 08+ ‚Ä¢ Supplemental VERIFY ONLY (no installs)\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# —á–∏—Ç–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º (–¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏; –Ω–∞ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–µ –≤–ª–∏—è–µ—Ç)\n",
        "source /content/soni_accel.env 2>/dev/null || true\n",
        ": \"${ACCEL:=cpu}\"\n",
        "echo \"ACCEL: ${ACCEL}\"\n",
        "\n",
        "echo \"== VERIFY ONLY (no new installs) ==\"\n",
        "python - <<'PY'\n",
        "import importlib, sys\n",
        "\n",
        "def check(name, extra=None):\n",
        "    try:\n",
        "        m = importlib.import_module(name)\n",
        "        ver = getattr(m, \"__version__\", \"?\")\n",
        "        tail = \"\"\n",
        "        if name == \"torch\":\n",
        "            try:\n",
        "                import torch\n",
        "                tail = f\"; cuda={torch.cuda.is_available()}; devices={(torch.cuda.device_count() if torch.cuda.is_available() else 0)}\"\n",
        "            except Exception:\n",
        "                pass\n",
        "        if name == \"onnxruntime\":\n",
        "            try:\n",
        "                providers = m.get_available_providers()\n",
        "                tail = f\"; providers={providers}\"\n",
        "            except Exception as e:\n",
        "                tail = f\"; providers=ERR({e})\"\n",
        "        print(f\"{name:12s} : ok (version {ver}{tail})\")\n",
        "    except Exception as e:\n",
        "        print(f\"{name:12s} : FAIL ({e})\")\n",
        "\n",
        "# –±–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏; –ù–ò–ß–ï–ì–û –Ω–µ —Å—Ç–∞–≤–∏–º\n",
        "for pkg in [\"torch\",\"torchvision\",\"torchaudio\",\"gradio\",\"onnxruntime\"]:\n",
        "    check(pkg)\n",
        "PY\n"
      ],
      "metadata": {
        "id": "UtxhnKTjGaOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title STEP 09 ‚Ä¢ GPU heavy install & verify (auto-skip on CPU) { display-mode: \"form\" }\n",
        "INSTALL_PIPER_TTS = True   # @param {type:\"boolean\"}\n",
        "INSTALL_COQUI_XTTS = True  # @param {type:\"boolean\"}\n",
        "\n",
        "import os, textwrap, tempfile, subprocess, sys\n",
        "\n",
        "# –°–¥–µ–ª–∞—Ç—å —Ç—É–º–±–ª–µ—Ä—ã –≤–∏–¥–∏–º—ã–º–∏ –¥–ª—è bash-—Å–∫—Ä–∏–ø—Ç–∞\n",
        "os.environ[\"INSTALL_PIPER_TTS\"]  = \"1\" if INSTALL_PIPER_TTS else \"0\"\n",
        "os.environ[\"INSTALL_COQUI_XTTS\"] = \"1\" if INSTALL_COQUI_XTTS else \"0\"\n",
        "\n",
        "SCRIPT = \"\"\"\n",
        "set -euo pipefail\n",
        "\n",
        "# ==== ACCEL ====\n",
        "source /content/soni_accel.env 2>/dev/null || true\n",
        ": \"${ACCEL:=cpu}\"\n",
        "if [[ \"$ACCEL\" != \"gpu\" ]]; then\n",
        "  echo \"GPU : skip (ACCEL=$ACCEL)\"\n",
        "  exit 0\n",
        "fi\n",
        "\n",
        "# ==== FLAGS (–∏–∑ —Ñ–æ—Ä–º—ã) ====\n",
        ": \"${INSTALL_PIPER_TTS:=1}\"\n",
        ": \"${INSTALL_COQUI_XTTS:=1}\"\n",
        "INSTALL_PIPER=\"${INSTALL_PIPER_TTS}\"\n",
        "INSTALL_XTTS=\"${INSTALL_COQUI_XTTS}\"\n",
        "INSTALL_TTS_NODEPS=\"${INSTALL_COQUI_XTTS}\"\n",
        "\n",
        "# ==== ENV ====\n",
        "if [[ -z \"${TORCH_INDEX_URL:-}\" ]]; then\n",
        "  export TORCH_INDEX_URL=\"https://download.pytorch.org/whl/cu124\"\n",
        "fi\n",
        "export PIP_DISABLE_PIP_VERSION_CHECK=1\n",
        "export PIP_USE_PEP517=1\n",
        "export PIP_PREFER_BINARY=1\n",
        "[[ -d /content/_wheels ]] && export PIP_FIND_LINKS=\"/content/_wheels${PIP_FIND_LINKS:+ $PIP_FIND_LINKS}\"\n",
        "\n",
        "CFILE=\"/content/constraints_sonitranslate.txt\"\n",
        "CARG=()\n",
        "[[ -s \"$CFILE\" ]] && CARG=(--constraint \"$CFILE\")\n",
        "\n",
        "# ==== CWD ====\n",
        "if [[ -d /content/SoniTranslate_installtest ]]; then\n",
        "  cd /content/SoniTranslate_installtest\n",
        "elif [[ -d /content/SoniTranslate ]]; then\n",
        "  cd /content/SoniTranslate\n",
        "fi\n",
        "\n",
        "status_line () {\n",
        "  if [[ \"$2\" == \"ok\" ]]; then echo \"$1 : ok $3\"; else echo \"$1 : FAIL $3\"; fi\n",
        "}\n",
        "\n",
        "# ==== SYSTEM ====\n",
        "sudo apt-get -y -qq update >/dev/null 2>&1 || true\n",
        "if sudo apt-get -y -qq install git-lfs >/dev/null 2>&1 && git lfs install >/dev/null 2>&1; then\n",
        "  status_line \"git-lfs\" \"ok\" \"\"\n",
        "else\n",
        "  status_line \"git-lfs\" \"FAIL\" \"\"\n",
        "fi\n",
        "\n",
        "if sudo apt-get -y -qq install libcudnn8 >/dev/null 2>&1; then\n",
        "  status_line \"libcudnn8\" \"ok\" \"\"\n",
        "else\n",
        "  status_line \"libcudnn8\" \"FAIL\" \"\"\n",
        "fi\n",
        "\n",
        "# ==== ONNXRUNTIME-GPU ====\n",
        "if uv run python -m pip install -q onnxruntime-gpu \"${CARG[@]}\"; then\n",
        "  py_out=\"$(python - <<'PY'\n",
        "import json\n",
        "try:\n",
        "    import onnxruntime as ort\n",
        "    out = {\"ok\": True, \"ver\": getattr(ort,\"__version__\",None),\n",
        "           \"providers\": ort.get_available_providers()}\n",
        "except Exception as e:\n",
        "    out = {\"ok\": False, \"err\": str(e)}\n",
        "print(json.dumps(out))\n",
        "PY\n",
        ")\"\n",
        "  ok=$(python - <<'PY' <<<\"$py_out\"\n",
        "import json,sys\n",
        "print('ok' if json.loads(sys.stdin.read())['ok'] else 'FAIL')\n",
        "PY\n",
        ")\n",
        "  if [[ \"$ok\" == \"ok\" ]]; then\n",
        "    ver=$(python - <<'PY' <<<\"$py_out\"\n",
        "import json,sys; d=json.loads(sys.stdin.read()); print(d['ver'])\n",
        "PY\n",
        ")\n",
        "    prov=$(python - <<'PY' <<<\"$py_out\"\n",
        "import json,sys; d=json.loads(sys.stdin.read()); print(','.join(d.get('providers',[])))\n",
        "PY\n",
        ")\n",
        "    status_line \"onnxruntime-gpu\" \"ok\" \"(version $ver; providers: $prov)\"\n",
        "  else\n",
        "    err=$(python - <<'PY' <<<\"$py_out\"\n",
        "import json,sys; d=json.loads(sys.stdin.read()); print(d.get('err',''))\n",
        "PY\n",
        ")\n",
        "    status_line \"onnxruntime-gpu\" \"FAIL\" \"($err)\"\n",
        "  fi\n",
        "else\n",
        "  status_line \"onnxruntime-gpu\" \"FAIL\" \"(pip)\"\n",
        "fi\n",
        "\n",
        "# ==== Piper (optional) ====\n",
        "if [[ \"$INSTALL_PIPER\" == \"1\" ]]; then\n",
        "  if uv run python -m pip install -q piper-tts \"${CARG[@]}\"; then\n",
        "    py_ok=\"$(python - <<'PY'\n",
        "try:\n",
        "    import piper as _p; print(\"ok (version %s)\" % getattr(_p,'__version__','?'))\n",
        "except Exception as e:\n",
        "    print(\"FAIL (%s)\" % e)\n",
        "PY\n",
        ")\"\n",
        "    [[ \"$py_ok\" == ok* ]] && status_line \"piper-tts\" \"ok\" \"(${py_ok#ok })\" || status_line \"piper-tts\" \"FAIL\" \"(${py_ok#FAIL })\"\n",
        "  else\n",
        "    status_line \"piper-tts\" \"FAIL\" \"(pip)\"\n",
        "  fi\n",
        "else\n",
        "  echo \"piper-tts : skip\"\n",
        "fi\n",
        "\n",
        "# ==== Coqui XTTS (optional) ====\n",
        "if [[ \"$INSTALL_XTTS\" == \"1\" ]]; then\n",
        "  if [[ -f requirements_xtts.txt ]]; then\n",
        "    if uv run python -m pip install -q -r requirements_xtts.txt \"${CARG[@]}\"; then\n",
        "      status_line \"requirements_xtts\" \"ok\" \"\"\n",
        "    else\n",
        "      status_line \"requirements_xtts\" \"FAIL\" \"\"\n",
        "    fi\n",
        "  else\n",
        "    status_line \"requirements_xtts\" \"FAIL\" \"(file not found)\"\n",
        "  fi\n",
        "else\n",
        "  echo \"requirements_xtts : skip\"\n",
        "fi\n",
        "\n",
        "# ==== TTS --no-deps (optional, with XTTS) ====\n",
        "if [[ \"$INSTALL_TTS_NODEPS\" == \"1\" ]]; then\n",
        "  if uv run python -m pip install -q TTS --no-deps \"${CARG[@]}\"; then\n",
        "    py_ok=\"$(python - <<'PY'\n",
        "try:\n",
        "    import TTS as _tts; print(\"ok (version %s)\" % getattr(_tts,'__version__','?'))\n",
        "except Exception as e:\n",
        "    print(\"FAIL (%s)\" % e)\n",
        "PY\n",
        ")\"\n",
        "    [[ \"$py_ok\" == ok* ]] && status_line \"TTS (no-deps)\" \"ok\" \"(${py_ok#ok })\" || status_line \"TTS (no-deps)\" \"FAIL\" \"(${py_ok#FAIL })\"\n",
        "  else\n",
        "    status_line \"TTS (no-deps)\" \"FAIL\" \"(pip)\"\n",
        "  fi\n",
        "else\n",
        "  echo \"TTS (no-deps) : skip\"\n",
        "fi\n",
        "\"\"\"\n",
        "\n",
        "# –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º bash-—Å–∫—Ä–∏–ø—Ç\n",
        "with tempfile.NamedTemporaryFile(\"w\", delete=False, suffix=\".sh\") as f:\n",
        "    f.write(textwrap.dedent(SCRIPT))\n",
        "    path = f.name\n",
        "\n",
        "rc = subprocess.call([\"bash\", path])\n",
        "if rc != 0:\n",
        "    print(f\"[STEP 09] failed (rc={rc})\", file=sys.stderr)\n"
      ],
      "metadata": {
        "id": "ItqV00c8KgPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWchIMyMECyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [STEP 10REPORT] –û—Ç—á—ë—Ç –ø–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ #@param\n",
        "#@title üîÄ Report builder & downloader (GPU data only when ACCEL=gpu)\n",
        "#@markdown **–†–µ–∂–∏–º –æ—Ç—á—ë—Ç–∞** –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ:\n",
        "REPORT_MODE = \"diff\"  #@param [\"diff\", \"full\"] {allow-input: false}\n",
        "AUTO_DOWNLOAD = True  #@param {type:\"boolean\"}\n",
        "ZIP_LOGS      = True  #@param {type:\"boolean\"}\n",
        "\n",
        "import os, re, json, zipfile, pkg_resources, io, sys, subprocess, shlex\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------- ACCEL fork ----------\n",
        "ACCEL = \"cpu\"\n",
        "accel_env = Path(\"/content/soni_accel.env\")\n",
        "if accel_env.exists():\n",
        "    for line in accel_env.read_text(encoding=\"utf-8\").splitlines():\n",
        "        if line.startswith(\"export ACCEL=\"):\n",
        "            ACCEL = line.split(\"=\",1)[1].strip().strip('\"')\n",
        "            break\n",
        "DO_GPU = (ACCEL == \"gpu\")\n",
        "print(f\"ACCEL: {ACCEL}  |  GPU checks: {'ON' if DO_GPU else 'OFF'}\")\n",
        "\n",
        "# ---------- paths ----------\n",
        "OUT_DIR   = Path(\"/content/_install_logs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUT_TXT   = OUT_DIR / \"08report.txt\"\n",
        "OUT_SUM   = OUT_DIR / \"08report_summary.txt\"\n",
        "OUT_DIFF  = OUT_DIR / \"08report_diff.txt\"\n",
        "ZIP_PATH  = Path(\"/content/sonitranslate_install_logs.zip\")\n",
        "\n",
        "# ---------- helper ----------\n",
        "def run(cmd: str):\n",
        "    try:\n",
        "        out = subprocess.check_output(shlex.split(cmd), stderr=subprocess.STDOUT, text=True)\n",
        "        return 0, out.strip()\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        return e.returncode, e.output.strip()\n",
        "    except Exception as e:\n",
        "        return -1, str(e)\n",
        "\n",
        "# –ü–µ—Ä–µ–π—Ç–∏ –≤ –∫–æ–ø–∏—é –ø—Ä–æ–µ–∫—Ç–∞, –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "proj_dir = Path(\"/content/SoniTranslate_installtest\")\n",
        "if proj_dir.exists():\n",
        "    os.chdir(proj_dir)\n",
        "\n",
        "# ---------- collect requirements *.txt ----------\n",
        "req_files = sorted([str(p) for p in Path(\".\").glob(\"requirements*.txt\")])\n",
        "if not req_files:\n",
        "    print(\"[warn] no requirements*.txt found in CWD; run this inside SoniTranslate_installtest\")\n",
        "    print(f\"Report saved to: {OUT_TXT}\")\n",
        "    OUT_TXT.write_text(\"[warn] no requirements*.txt found\\n\", encoding=\"utf-8\")\n",
        "    OUT_SUM.write_text(\"[warn] no requirements*.txt found\\n\", encoding=\"utf-8\")\n",
        "else:\n",
        "    # 1) desired from files\n",
        "    tmp_req = []\n",
        "    for rf in req_files:\n",
        "        with open(rf, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            for line in f:\n",
        "                s = re.sub(r\"#.*\", \"\", line).strip()\n",
        "                if not s or s.startswith(\"-e\") or s.startswith(\"--\"):\n",
        "                    continue\n",
        "                m = re.match(r\"^([A-Za-z0-9_.-]+)(\\[.*\\])?([<>=!~]=.*)?\", s)\n",
        "                if m:\n",
        "                    name = m.group(1).lower()\n",
        "                    spec = m.group(3) or \"\"\n",
        "                    tmp_req.append((name, spec))\n",
        "\n",
        "    # 2) filter interesting pkgs (–¥–æ–±–∞–≤–∏–ª onnxruntime –∏ piper-tts)\n",
        "    keep_re = re.compile(\n",
        "        r\"^(numpy|scipy|websockets|opencv-python|TTS|transformers|sentence-transformers|tokenizers|\"\n",
        "        r\"gradio|gradio-client|torch|torchvision|torchaudio|pyannote\\.audio|whisperx|onnxruntime|piper-tts)$\",\n",
        "        re.I,\n",
        "    )\n",
        "    want = {}\n",
        "    for name, spec in tmp_req:\n",
        "        if keep_re.match(name):\n",
        "            want[name] = spec\n",
        "\n",
        "    # 3) installed in env\n",
        "    installed = {}\n",
        "    for d in pkg_resources.working_set:\n",
        "        n = d.project_name\n",
        "        if keep_re.match(n):\n",
        "            installed[n.lower()] = d.version\n",
        "\n",
        "    # 4) summary\n",
        "    all_pkgs = sorted(set(want.keys()) | set(installed.keys()))\n",
        "    summary_lines = []\n",
        "    header = f\"{'package':24s} | {'requirement':22s} | {'installed':18s}\\n\" \\\n",
        "             f\"{'-'*24}-+-{'-'*22}-+-{'-'*18}\\n\"\n",
        "    summary_lines.append(header)\n",
        "    for p in all_pkgs:\n",
        "        req = want.get(p, \"\") or \"(none)\"\n",
        "        inst = installed.get(p, \"\") or \"(absent)\"\n",
        "        summary_lines.append(f\"{p:24s} | {req:22s} | {inst:18s}\\n\")\n",
        "\n",
        "    # 5) hints + diff (–º–∏–Ω–∏–º—É–º —Ç—Ä–æ–≥–∞–µ–º)\n",
        "    def vtuple(t):\n",
        "        return tuple(int(x) for x in re.findall(r\"\\d+\", t)[:3]) if t else None\n",
        "\n",
        "    hints = []\n",
        "    diff_rows = []\n",
        "\n",
        "    for p in all_pkgs:\n",
        "        req = want.get(p, \"\")\n",
        "        inst = installed.get(p)\n",
        "        if not inst:\n",
        "            diff_rows.append((p, req or \"(none)\", \"(absent)\", \"absent\"))\n",
        "            continue\n",
        "        if not req:\n",
        "            diff_rows.append((p, \"(none)\", inst, \"un pinned\"))\n",
        "\n",
        "    tr = installed.get(\"transformers\"); tok = installed.get(\"tokenizers\")\n",
        "    if tr and tok and vtuple(tok) and vtuple(tr):\n",
        "        if vtuple(tok) < (0,16) and vtuple(tr) >= (4,37):\n",
        "            hints.append(f\"- transformers/tokenizers: tokenizers {tok} <0.16 with transformers {tr} ‚â•4.37\")\n",
        "\n",
        "    # ---------- RUNTIME CHECKS with FORK ----------\n",
        "    runtime_checks = []\n",
        "    # –æ–±—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ (–Ω–µ GPU-–∑–∞–≤–∏—Å–∏–º—ã–µ)\n",
        "    try:\n",
        "        import gradio as _gr\n",
        "        runtime_checks.append((\"gradio\", True, f\"version {getattr(_gr,'__version__','?')}\"))\n",
        "    except Exception as e:\n",
        "        runtime_checks.append((\"gradio\", False, str(e)))\n",
        "\n",
        "    # GPU-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Äî –¢–û–õ–¨–ö–û –µ—Å–ª–∏ ACCEL=gpu\n",
        "    if DO_GPU:\n",
        "        # torch cuda\n",
        "        try:\n",
        "            import torch as _t\n",
        "            runtime_checks.append((\"torch\", True, f\"version {_t.__version__}; cuda={_t.cuda.is_available()}; devices={_t.cuda.device_count() if _t.cuda.is_available() else 0}\"))\n",
        "        except Exception as e:\n",
        "            runtime_checks.append((\"torch\", False, str(e)))\n",
        "\n",
        "        # onnxruntime providers\n",
        "        try:\n",
        "            import onnxruntime as _ort\n",
        "            runtime_checks.append((\"onnxruntime\", True, f\"version {_ort.__version__}; providers={_ort.get_available_providers()}\"))\n",
        "        except Exception as e:\n",
        "            runtime_checks.append((\"onnxruntime\", False, str(e)))\n",
        "\n",
        "        # piper / TTS (–æ–Ω–∏ —Å—Ç–∞–≤—è—Ç—Å—è –Ω–∞ GPU-–≤–µ—Ç–∫–µ —É —Ç–µ–±—è)\n",
        "        try:\n",
        "            import piper as _p; runtime_checks.append((\"piper-tts\", True, f\"version {getattr(_p,'__version__','?')}\"))\n",
        "        except Exception as e:\n",
        "            runtime_checks.append((\"piper-tts\", False, str(e)))\n",
        "        try:\n",
        "            import TTS as _tts; runtime_checks.append((\"TTS\", True, f\"version {getattr(_tts,'__version__','?')}\"))\n",
        "        except Exception as e:\n",
        "            runtime_checks.append((\"TTS\", False, str(e)))\n",
        "\n",
        "        # libcudnn8 –Ω–∞–ª–∏—á–∏–µ (dpkg)\n",
        "        rc, out = run(\"dpkg -s libcudnn8\")\n",
        "        lib_ok = (rc==0 and \"Status: install ok installed\" in out)\n",
        "        runtime_checks.append((\"libcudnn8\", lib_ok, f\"rc={rc}\"))\n",
        "\n",
        "        # git-lfs (–æ–±—â–∏–π, –Ω–æ –æ—Å—Ç–∞–≤–∏–º —Ç—É—Ç, —á—Ç–æ–±—ã –¥–≤–∞–∂–¥—ã –Ω–µ –ø–µ—á–∞—Ç–∞—Ç—å)\n",
        "        rc, out = run(\"git lfs version\")\n",
        "        runtime_checks.append((\"git-lfs\", rc==0, out.splitlines()[0] if out else \"\"))\n",
        "\n",
        "    # ---------- WRITE FILES ----------\n",
        "    OUT_TXT.write_text(\n",
        "        \"== requirements files ==\\n\" + \"\\n\".join(f\" - {x}\" for x in req_files) + \"\\n\\n\"\n",
        "        + \"== SUMMARY (desired vs installed) ==\\n\" + \"\".join(summary_lines)\n",
        "        + ( \"\\n== HINTS ==\\n\" + \"\\n\".join(hints) + \"\\n\" if (REPORT_MODE == \"full\" and hints) else \"\" )\n",
        "        + ( \"\\n== RUNTIME CHECKS (GPU only) ==\\n\" + \"\\n\".join(f\"{n:12s} : {'ok' if ok else 'FAIL'} ({info})\" for n,ok,info in runtime_checks) + \"\\n\" if runtime_checks else \"\"),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "\n",
        "    OUT_SUM.write_text(\n",
        "        \"== requirements files ==\\n\" + \"\\n\".join(f\" - {x}\" for x in req_files) + \"\\n\\n\"\n",
        "        + \"== SUMMARY (desired vs installed) ==\\n\" + \"\".join(summary_lines),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "\n",
        "    if diff_rows:\n",
        "        with OUT_DIFF.open(\"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"package | requirement | installed | note\\n\")\n",
        "            f.write(\"-\"*70 + \"\\n\")\n",
        "            for p, req, inst, note in diff_rows:\n",
        "                f.write(f\"{p:24s} | {req:22s} | {inst:18s} | {note}\\n\")\n",
        "\n",
        "    # ---------- PRINT ----------\n",
        "    print(\"== requirements files ==\")\n",
        "    for x in req_files:\n",
        "        print(\" -\", x)\n",
        "    print(\"\\n== SUMMARY (desired vs installed) ==\")\n",
        "    sys.stdout.write(\"\".join(summary_lines))\n",
        "    if runtime_checks:\n",
        "        print(\"\\n== RUNTIME CHECKS (GPU only) ==\")\n",
        "        for n, ok, info in runtime_checks:\n",
        "            print(f\"{n:12s} : {'ok' if ok else 'FAIL'} ({info})\")\n",
        "\n",
        "# ---------- pack & download ----------\n",
        "def colab_download(path: Path):\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        if path.exists():\n",
        "            files.download(str(path))\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass\n",
        "    return False\n",
        "\n",
        "prefer_diff = REPORT_MODE == \"diff\" and OUT_DIFF.exists() and OUT_DIFF.stat().st_size > 0\n",
        "target = OUT_DIFF if prefer_diff else OUT_TXT\n",
        "print(f\"\\nReport saved to: {target}\")\n",
        "\n",
        "if ZIP_LOGS:\n",
        "    with zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(str(OUT_DIR)):\n",
        "            for fname in files:\n",
        "                if fname.endswith(\".log\") or fname.startswith(\"08report\"):\n",
        "                    fp = Path(root) / fname\n",
        "                    zf.write(fp, fp.relative_to(\"/content\"))\n",
        "    print(f\"Logs zip: {ZIP_PATH}\")\n",
        "\n",
        "if AUTO_DOWNLOAD:\n",
        "    _ok = colab_download(target)\n",
        "    if ZIP_LOGS:\n",
        "        _ok_zip = colab_download(ZIP_PATH)\n",
        "    if not _ok:\n",
        "        print(\"Note: files.download() —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ Google Colab.\")\n"
      ],
      "metadata": {
        "id": "QyaH0ikFEQkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title STEP 09L ‚Ä¢ Light runtime deps install + mini report\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "echo \"== LIGHT DEPS INSTALL (rarfile, srt, ffmpeg-python; system ffmpeg if missing) ==\"\n",
        "\n",
        "# system ffmpeg (–µ—Å–ª–∏ –Ω–µ—Ç)\n",
        "if ! command -v ffmpeg >/dev/null 2>&1; then\n",
        "  sudo apt-get -y -qq update >/dev/null 2>&1 || true\n",
        "  sudo apt-get -y -qq install ffmpeg >/dev/null 2>&1 || true\n",
        "fi\n",
        "\n",
        "# python deps\n",
        "uv run python -m pip install -q rarfile srt ffmpeg-python\n",
        "\n",
        "# report\n",
        "python - <<'PY'\n",
        "import importlib, shutil, subprocess\n",
        "\n",
        "def line(name, ok, info=\"\"):\n",
        "    print(f\"{name:14s} : {'ok' if ok else 'FAIL'}{(' ' + info) if info else ''}\")\n",
        "\n",
        "print(\"== SYSTEM ==\")\n",
        "ff = shutil.which(\"ffmpeg\")\n",
        "if ff:\n",
        "    try:\n",
        "        ver = subprocess.check_output([ff,\"-version\"],text=True).splitlines()[0]\n",
        "    except Exception as e:\n",
        "        ver=f\"ERR({e})\"\n",
        "    line(\"ffmpeg\",True,f\"({ver})\")\n",
        "else:\n",
        "    line(\"ffmpeg\",False,\"(not found)\")\n",
        "\n",
        "print(\"\\n== PYTHON PACKAGES ==\")\n",
        "for mod in (\"rarfile\",\"srt\",\"ffmpeg\"):\n",
        "    try:\n",
        "        m=importlib.import_module(mod)\n",
        "        v=getattr(m,\"__version__\",\"?\")\n",
        "        line(mod,True,f\"(version {v})\")\n",
        "    except Exception as e:\n",
        "        line(mod,False,f\"({e})\")\n",
        "PY\n"
      ],
      "metadata": {
        "id": "mdlgyzd6Qyhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title HOTFIX ‚Ä¢ install faiss-cpu (for CPU run) + verify\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "echo \"== installing faiss-cpu ==\"\n",
        "uv run python -m pip install -q faiss-cpu\n",
        "\n",
        "python - <<'PY'\n",
        "try:\n",
        "    import faiss\n",
        "    v = getattr(faiss, '__version__', '?')\n",
        "    print(f\"faiss : ok (version {v}; CPU-only build)\")\n",
        "except Exception as e:\n",
        "    print(\"faiss : FAIL\", e)\n",
        "PY\n"
      ],
      "metadata": {
        "id": "4wVS9xw6Vcpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title HOTFIX ‚Ä¢ install praat-parselmouth (parselmouth) + verify\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "uv run python -m pip install -q praat-parselmouth\n",
        "python - <<'PY'\n",
        "try:\n",
        "    import parselmouth\n",
        "    print(\"parselmouth : ok (version %s)\" % getattr(parselmouth, \"__version__\", \"?\"))\n",
        "except Exception as e:\n",
        "    print(\"parselmouth : FAIL\", e)\n",
        "PY\n"
      ],
      "metadata": {
        "id": "YLi7F1OFWGGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title STEP 09L-auto ‚Ä¢ scan imports, install light deps, re-check\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# --- –≤ –∫–∞–∫—É—é –ø–∞–ø–∫—É —Å–º–æ—Ç—Ä–µ—Ç—å –∫–æ–¥ ---\n",
        "if [[ -d /content/SoniTranslate_installtest ]]; then\n",
        "  cd /content/SoniTranslate_installtest\n",
        "elif [[ -d /content/SoniTranslate ]]; then\n",
        "  cd /content/SoniTranslate\n",
        "else\n",
        "  echo \"ERROR: repo folder not found\"; exit 2\n",
        "fi\n",
        "\n",
        "# --- –ø—Ä–æ—á–∏—Ç–∞–µ–º ACCEL –¥–ª—è faiss –º–∞–ø–ø–∏–Ω–≥–∞ ---\n",
        "source /content/soni_accel.env 2>/dev/null || true\n",
        ": \"${ACCEL:=cpu}\"\n",
        "\n",
        "python - <<'PY'\n",
        "import os, re, sys, shutil, subprocess, json, pathlib, importlib\n",
        "\n",
        "ROOT = pathlib.Path.cwd()\n",
        "\n",
        "# 1) —Å–æ–±—Ä–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ import-—Å—Ç—Ä–æ–∫\n",
        "mods = set()\n",
        "pat_import = re.compile(r'^\\s*import\\s+([A-Za-z0-9_\\.]+)')\n",
        "pat_from   = re.compile(r'^\\s*from\\s+([A-Za-z0-9_\\.]+)\\s+import\\s+')\n",
        "\n",
        "for p in ROOT.rglob(\"*.py\"):\n",
        "    try:\n",
        "        with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            for line in f:\n",
        "                m = pat_import.match(line)\n",
        "                if m:\n",
        "                    mods.add(m.group(1).split('.')[0])\n",
        "                m = pat_from.match(line)\n",
        "                if m:\n",
        "                    mods.add(m.group(1).split('.')[0])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# 2) –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏ \"import name\" -> \"pip package\"\n",
        "#    (–∑–¥–µ—Å—å —Ç–æ–ª—å–∫–æ –ª—ë–≥–∫–∏–µ/—á–∞—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º—ã–µ)\n",
        "ACCEL = os.environ.get(\"ACCEL\",\"cpu\")\n",
        "pip_map = {\n",
        "    \"ffmpeg\":        \"ffmpeg-python\",\n",
        "    \"rarfile\":       \"rarfile\",\n",
        "    \"srt\":           \"srt\",\n",
        "    \"faiss\":         \"faiss-gpu\" if ACCEL==\"gpu\" else \"faiss-cpu\",\n",
        "    \"parselmouth\":   \"praat-parselmouth\",\n",
        "    \"pyworld\":       \"pyworld\",\n",
        "    \"torchcrepe\":    \"torchcrepe\",\n",
        "    \"librosa\":       \"librosa\",\n",
        "}\n",
        "\n",
        "# 3) –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è\n",
        "missing = []\n",
        "report = []\n",
        "def try_import(name):\n",
        "    try:\n",
        "        importlib.import_module(name)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "# –ø–ª—é—Å —Å–∏—Å—Ç–µ–º–Ω—ã–π ffmpeg\n",
        "ffmpeg_path = shutil.which(\"ffmpeg\")\n",
        "\n",
        "for name in sorted(mods):\n",
        "    if name in pip_map:\n",
        "        ok = try_import(name)\n",
        "        report.append((name, ok, pip_map[name]))\n",
        "        if not ok:\n",
        "            missing.append(name)\n",
        "\n",
        "# —Ä–∞—Å–ø–µ—á–∞—Ç–∞—Ç—å –ø–µ—Ä–≤–∏—á–Ω—ã–π –æ—Ç—á—ë—Ç\n",
        "print(\"== PRIMARY CHECK (before install) ==\")\n",
        "for name, ok, pkg in report:\n",
        "    print(f\"{name:14s} : {'ok' if ok else 'MISSING'}  -> pip: {pkg}\")\n",
        "print(f\"system ffmpeg : {'ok ('+ffmpeg_path+')' if ffmpeg_path else 'MISSING'}\")\n",
        "sys.stdout.flush()\n",
        "\n",
        "# 4) —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–æ–≥–æ, —á—Ç–æ –∏–∑–≤–µ—Å—Ç–Ω–æ –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç\n",
        "to_install = [pip_map[n] for n in missing]\n",
        "# system ffmpeg ‚Äî –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç\n",
        "need_ffmpeg = (ffmpeg_path is None)\n",
        "\n",
        "INSTALL_SUMMARY = {\"pip_install\": to_install, \"apt_ffmpeg\": need_ffmpeg}\n",
        "print(\"\\n== PLAN ==\")\n",
        "print(json.dumps(INSTALL_SUMMARY, indent=2))\n",
        "\n",
        "# –≤—ã–ø–æ–ª–Ω—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, shell=True, check=False,\n",
        "                          stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "if need_ffmpeg:\n",
        "    run(\"sudo apt-get -y -qq update >/dev/null 2>&1 || true\")\n",
        "    run(\"sudo apt-get -y -qq install ffmpeg >/dev/null 2>&1 || true\")\n",
        "\n",
        "if to_install:\n",
        "    run(\"uv run python -m pip install -q \" + \" \".join(to_install))\n",
        "\n",
        "# 5) –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
        "ffmpeg_path2 = shutil.which(\"ffmpeg\")\n",
        "post = []\n",
        "fail_any = False\n",
        "for name, _, pkg in report:\n",
        "    ok2 = try_import(name)\n",
        "    post.append((name, ok2, pkg))\n",
        "    if not ok2:\n",
        "        fail_any = True\n",
        "\n",
        "print(\"\\n== SECONDARY CHECK (after install) ==\")\n",
        "for name, ok2, pkg in post:\n",
        "    print(f\"{name:14s} : {'ok' if ok2 else 'FAIL'}  -> pip: {pkg}\")\n",
        "print(f\"system ffmpeg : {'ok ('+ffmpeg_path2+')' if ffmpeg_path2 else 'FAIL'}\")\n",
        "\n",
        "# –ö–æ—Ä–æ—Ç–∫–∏–π –∏—Ç–æ–≥ –¥–ª—è –Ω–æ—É—Ç–±—É–∫–∞ (non-zero rc —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ —Ç–∞–∫ –∏ –Ω–µ —Å—Ç–∞–ª–æ)\n",
        "if fail_any or (ffmpeg_path2 is None):\n",
        "    print(\"\\n[RESULT] Some deps are still missing. See lines above.\")\n",
        "    sys.exit(1)\n",
        "else:\n",
        "    print(\"\\n[RESULT] Light deps look good.\")\n",
        "PY\n"
      ],
      "metadata": {
        "id": "IY6krR0IW-Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title HOTFIX ‚Ä¢ install torchcrepe + minimal verify\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "echo \"== installing torchcrepe ==\"\n",
        "uv run python -m pip install -q torchcrepe\n",
        "\n",
        "python - <<'PY'\n",
        "try:\n",
        "    import torchcrepe, torch\n",
        "    v = getattr(torchcrepe, \"__version__\", \"?\")\n",
        "    print(f\"torchcrepe : ok (version {v}; torch {torch.__version__})\")\n",
        "except Exception as e:\n",
        "    print(\"torchcrepe : FAIL\", e)\n",
        "PY\n"
      ],
      "metadata": {
        "id": "v3XOpvQzXy-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title RUN THE WEB APP (robust runner with logs & preflight)\n",
        "YOUR_HF_TOKEN = \"\"  # @param {type:\"string\"}\n",
        "theme = \"Taithrah/Minimal\"  # @param [\"Taithrah/Minimal\",\"aliabid94/new-theme\",\"gstaff/xkcd\",\"ParityError/LimeFace\",\"abidlabs/pakistan\",\"rottenlittlecreature/Moon_Goblin\",\"ysharma/llamas\",\"gradio/dracula_revamped\"]\n",
        "interface_language = \"english\"  # @param ['arabic','azerbaijani','chinese_zh_cn','english','french','german','hindi','indonesian','italian','japanese','korean','marathi','polish','portuguese','russian','spanish','swedish','turkish','ukrainian','vietnamese']\n",
        "verbosity_level = \"info\"  # @param [\"debug\",\"info\",\"warning\",\"error\",\"critical\"]\n",
        "\n",
        "import os, pathlib, subprocess, shlex, sys, textwrap\n",
        "\n",
        "# 0) HF token: –ø–æ–ª–µ > secrets; –ø—É—Å—Ç–æ–π –¥–æ–ø—É—Å—Ç–∏–º\n",
        "if not YOUR_HF_TOKEN:\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        YOUR_HF_TOKEN = userdata.get('YOUR_HF_TOKEN') or \"\"\n",
        "    except Exception:\n",
        "        YOUR_HF_TOKEN = \"\"\n",
        "os.environ[\"YOUR_HF_TOKEN\"] = YOUR_HF_TOKEN\n",
        "\n",
        "# 1) –≤—ã–±—Ä–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π CWD\n",
        "if pathlib.Path(\"/content/SoniTranslate\").is_dir():\n",
        "    os.chdir(\"/content/SoniTranslate\")\n",
        "elif pathlib.Path(\"/content/SoniTranslate_installtest\").is_dir():\n",
        "    os.chdir(\"/content/SoniTranslate_installtest\")\n",
        "else:\n",
        "    print(\"ERROR: repo not found at /content/SoniTranslate[_installtest].\", file=sys.stderr)\n",
        "    raise SystemExit(2)\n",
        "\n",
        "# 2) —Ñ–æ—Ä—Å–∏–º CPU, –µ—Å–ª–∏ ACCEL!=gpu (—É–±—Ä–∞—Ç—å —à—É–º –æ—Ç CUDA)\n",
        "ACCEL = \"cpu\"\n",
        "accel_env = \"/content/soni_accel.env\"\n",
        "if os.path.exists(accel_env):\n",
        "    for line in open(accel_env, \"r\", encoding=\"utf-8\"):\n",
        "        if line.startswith(\"export ACCEL=\"):\n",
        "            ACCEL = line.split(\"=\",1)[1].strip().strip('\"'); break\n",
        "if ACCEL != \"gpu\":\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "# 3) –ø—Ä–µ—Ñ–ª–∞–π—Ç: –ø—Ä–æ–≤–µ—Ä–∏–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥—É–ª–∏; –µ—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç ‚Äî —è–≤–Ω–æ –ø–æ–∫–∞–∂–µ–º\n",
        "missing = []\n",
        "def _try_import(name):\n",
        "    try:\n",
        "        __import__(name); return True\n",
        "    except Exception:\n",
        "        missing.append(name); return False\n",
        "\n",
        "print(\"CWD:\", os.getcwd())\n",
        "print(\"ACCEL:\", ACCEL)\n",
        "print(\"HF token set:\", \"yes\" if YOUR_HF_TOKEN else \"no\")\n",
        "\n",
        "# –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω—É–∂–Ω–æ–µ –¥–ª—è —Å—Ç–∞—Ä—Ç–∞\n",
        "for mod in [\"gradio\",\"torch\",\"ffmpeg\",\"rarfile\",\"srt\"]:\n",
        "    _try_import(mod)\n",
        "\n",
        "if missing:\n",
        "    print(\"\\n[PRE-FLIGHT] Missing python packages:\", \", \".join(missing))\n",
        "    print(\"Tip: run STEP 09L (light deps) again to install small runtime deps.\")\n",
        "else:\n",
        "    print(\"\\n[PRE-FLIGHT] imports: ok\")\n",
        "\n",
        "# 4) –∑–∞–ø—É—Å–∫ —Å –ª–æ–≥–∞–º–∏\n",
        "LOG_DIR = pathlib.Path(\"/content/_install_logs\"); LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "APP_LOG = LOG_DIR / \"app_run.log\"\n",
        "\n",
        "cmd = f\"python -u app_rvc.py --theme {shlex.quote(theme)} --verbosity_level {shlex.quote(verbosity_level)} --language {shlex.quote(interface_language)} --public_url\"\n",
        "print(\"\\nRUN:\", cmd)\n",
        "print(f\"Log: {APP_LOG}\")\n",
        "\n",
        "# –∑–∞–ø—É—Å–∫–∞–µ–º –∏ –ø–∏—à–µ–º –ª–æ–≥ (stream + —Ñ–∞–π–ª)\n",
        "with open(APP_LOG, \"w\", encoding=\"utf-8\") as lf:\n",
        "    proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
        "    # –æ–Ω–ª–∞–π–Ω –≤—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å\n",
        "    shown = 0\n",
        "    try:\n",
        "        for line in proc.stdout:\n",
        "            lf.write(line)\n",
        "            if shown < 50:\n",
        "                sys.stdout.write(line)\n",
        "                shown += 1\n",
        "    except Exception:\n",
        "        pass\n",
        "    proc.wait()\n",
        "    rc = proc.returncode\n",
        "\n",
        "if rc == 0:\n",
        "    print(\"\\n[OK] app_rvc.py exited with code 0 (see full log above / in file).\")\n",
        "else:\n",
        "    print(f\"\\n[FAIL] app_rvc.py exited with code {rc}. Last 200 log lines:\\n\")\n",
        "    try:\n",
        "        tail = subprocess.check_output([\"tail\",\"-n\",\"200\",str(APP_LOG)], text=True)\n",
        "        print(tail)\n",
        "    except Exception as e:\n",
        "        print(f\"(tail failed: {e})\")\n",
        "    # —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –ø—Ä–∏—á–∏–Ω—ã –∏ —á—Ç–æ –¥–µ–ª–∞—Ç—å\n",
        "    print(textwrap.dedent(\"\"\"\n",
        "    ---- QUICK DIAG ----\n",
        "    ‚Ä¢ ModuleNotFoundError ‚Üí –∑–∞–ø—É—Å—Ç–∏ STEP 09L (rarfile|srt|ffmpeg-python) –∏–ª–∏ 09 (GPU-—Ö–≤–æ—Å—Ç, –µ—Å–ª–∏ –Ω—É–∂–µ–Ω).\n",
        "    ‚Ä¢ 'ffmpeg' not found ‚Üí –≤ STEP 09L —Å—Ç–∞–≤–∏—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–π ffmpeg.\n",
        "    ‚Ä¢ CUDA/cudnn/cublas —Ä–µ–≥–∏—Å—Ç—Ä—ã –Ω–∞ CPU ‚Üí —ç—Ç–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è; –¥–ª—è CPU —Å–∫—Ä—ã–≤–∞–µ–º CUDA_VISIBLE_DEVICES.\n",
        "    ‚Ä¢ –ï—Å–ª–∏ –∫–ª—é—á–µ–≤–æ–π —Å—Ç–µ–∫ –Ω–µ –ø–æ—Å—Ç–∞–≤–∏–ª—Å—è –≤ 08/08 ‚Üí –≤–µ—Ä–Ω–∏—Å—å –∏ –ø—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ 08/08 (pip_* .log –≤ /content/_install_logs).\n",
        "    \"\"\"))\n",
        "    raise SystemExit(rc)\n"
      ],
      "metadata": {
        "id": "FU-IDkoQUCC6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
